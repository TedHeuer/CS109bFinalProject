{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "from sklearn import linear_model\n",
    "from sklearn import preprocessing\n",
    "from sklearn import tree\n",
    "from sklearn import ensemble\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.cross_validation import KFold\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import hamming_loss\n",
    "import StringIO\n",
    "import time\n",
    "import pickle\n",
    "from sklearn.datasets import make_multilabel_classification\n",
    "from sklearn.cross_decomposition import CCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "(5120, 'train sequences')\n",
      "(1704, 'test sequences')\n",
      "(8, 'classes.')\n",
      "Data loaded.\n"
     ]
    }
   ],
   "source": [
    "# Multi Label Model \n",
    "print('Loading data...')\n",
    "\n",
    "with open('full_dataset.pickle', 'rb') as handle:\n",
    "    dataset = pickle.load(handle)\n",
    "    \n",
    "print(len(dataset['train_x']), 'train sequences')\n",
    "print(len(dataset['test_x']), 'test sequences')\n",
    " \n",
    "num_classes = len(dataset['labels'])\n",
    "print(num_classes, 'classes.')\n",
    "\n",
    "print('Data loaded.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#found a nice example of extracting dominate color palette from image, modify a bit for our project\n",
    "#http://stackoverflow.com/a/16216866/190597 (Jaime)\n",
    "#http://stackoverflow.com/a/16840350/190597 (Jaime)\n",
    "def palette(img):\n",
    "    arr = np.asarray(img)\n",
    "    palette, index = np.unique(asvoid(arr).ravel(), return_inverse=True)\n",
    "    palette = palette.view(arr.dtype).reshape(-1, arr.shape[-1])\n",
    "    count = np.bincount(index)\n",
    "    order = np.argsort(count)\n",
    "    return palette[order[::-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#generate a pallatte score for the top 5 dominate color in this image\n",
    "#calculate color intensity for top 5 dominate color\n",
    "#calcuate average red, blue, green scale\n",
    "def getPaletteScore(img):\n",
    "    palettescore = np.sum(palette(img)[:5], axis = 1)\n",
    "    avgRBG = np.mean(palette(img)[:5], axis = 0)\n",
    "    tempRBG = [0.0, 0.0, 0.0] + avgRBG[:3]\n",
    "    return np.concatenate((palettescore[:5], tempRBG))\n",
    "def asvoid(arr):\n",
    "    arr = np.ascontiguousarray(arr)\n",
    "    return arr.view(np.dtype((np.void, arr.dtype.itemsize * arr.shape[-1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5120, 8)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_vals = np.array([])\n",
    "for row in dataset['train_x'].iterrows():\n",
    "    train_vals = np.concatenate((train_vals, getPaletteScore(row[1]['poster'])))\n",
    "train_x = train_vals.reshape(dataset['train_x'].shape[0], 8)\n",
    "train_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1704, 8)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_vals = np.array([])\n",
    "for row in dataset['test_x'].iterrows():\n",
    "    test_vals = np.concatenate((test_vals, getPaletteScore(row[1]['poster'])))\n",
    "test_x = test_vals.reshape(dataset['test_x'].shape[0], 8)\n",
    "test_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_y = dataset['train_y']\n",
    "test_y = dataset['test_y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3-fold cross validation:\n",
      "Evaluating trees : 1\n",
      "Best trees : 1 Best Depth : 3\n",
      "Evaluating trees : 6\n",
      "Best trees : 6 Best Depth : 2\n",
      "Evaluating trees : 11\n",
      "Best trees : 11 Best Depth : 2\n",
      "Evaluating trees : 16\n",
      "Best trees : 16 Best Depth : 5\n",
      "Evaluating trees : 21\n",
      "Best trees : 16 Best Depth : 5\n",
      "Evaluating trees : 26\n",
      "Best trees : 16 Best Depth : 5\n",
      "Evaluating trees : 31\n",
      "Best trees : 16 Best Depth : 5\n",
      "Evaluating trees : 36\n",
      "Best trees : 16 Best Depth : 5\n",
      "Evaluating trees : 41\n",
      "Best trees : 16 Best Depth : 5\n",
      "Evaluating trees : 46\n",
      "Best trees : 16 Best Depth : 5\n",
      "Evaluating trees : 51\n",
      "Best trees : 16 Best Depth : 5\n",
      "Evaluating trees : 56\n",
      "Best trees : 16 Best Depth : 5\n",
      "Evaluating trees : 61\n",
      "Best trees : 16 Best Depth : 5\n",
      "Evaluating trees : 66\n",
      "Best trees : 16 Best Depth : 5\n",
      "Evaluating trees : 71\n",
      "Best trees : 16 Best Depth : 5\n",
      "Evaluating trees : 76\n",
      "Best trees : 16 Best Depth : 5\n",
      "Evaluating trees : 81\n",
      "Best trees : 16 Best Depth : 5\n",
      "Evaluating trees : 86\n",
      "Best trees : 16 Best Depth : 5\n",
      "Evaluating trees : 91\n",
      "Best trees : 16 Best Depth : 5\n",
      "Evaluating trees : 96\n",
      "Best trees : 16 Best Depth : 5\n"
     ]
    }
   ],
   "source": [
    "n_trees = np.arange(1, 101, 5)  \n",
    "depths = np.arange(1, 15)   \n",
    "\n",
    "# To keep track of the best model\n",
    "best_score_mml = 1e15\n",
    "best_trees = 0\n",
    "best_depth = 0\n",
    "# Run grid search for model with 5-fold cross validation\n",
    "print '3-fold cross validation:'\n",
    "\n",
    "for trees in n_trees:\n",
    "    print('Evaluating trees : ' + str(trees))\n",
    "    for depth in depths:\n",
    "        # Cross validation for every experiment\n",
    "        k_folds_mml = KFold(train_x.shape[0], n_folds=3, shuffle=True)\n",
    "        scores_mml = []\n",
    "        for train_indices, validation_indices in k_folds_mml:\n",
    "            # Generate training data\n",
    "            x_train_cv_mml = train_x[train_indices]\n",
    "            y_train_cv_mml = train_y[train_indices]\n",
    "            # Generate validation data\n",
    "            x_validate_mml = train_x[validation_indices]\n",
    "            y_validate_mml = train_y[validation_indices]\n",
    "            \n",
    "            # Fit random forest on training data\n",
    "            model_mml = OneVsRestClassifier(ensemble.RandomForestClassifier(n_estimators=trees, max_depth=depth))\n",
    "            model_mml.fit(x_train_cv_mml, y_train_cv_mml)\n",
    "            # Score on validation data\n",
    "            y_pred_cv_mml = model_mml.predict(x_validate_mml)\n",
    "            scores_mml.append(hamming_loss(y_validate_mml, y_pred_cv_mml))\n",
    "        \n",
    "        # Record and report accuracy\n",
    "        average_score_mml = np.mean(scores_mml)\n",
    "        #print \"Trees:\", trees, \"Depth:\", depth, \"Loss:\", average_score_mml\n",
    "        \n",
    "        # Update our record of the best parameters see so far\n",
    "        if average_score_mml < best_score_mml:\n",
    "            best_score_mml = average_score_mml\n",
    "            best_trees = trees\n",
    "            best_depth = depth\n",
    "    print('Best trees : ' + str(best_trees) + ' Best Depth : ' + str(best_depth))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OneVsRestClassifier(estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=5, max_features='auto', max_leaf_nodes=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=16, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False),\n",
       "          n_jobs=1)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit model on entire train set using chosen number of trees and depth\n",
    "model_mml = OneVsRestClassifier(ensemble.RandomForestClassifier(n_estimators=best_trees, max_depth=best_depth))\n",
    "model_mml.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chosen number of trees, depth: 16 , 5\n",
      "Test F1 Score: 0.360680751174\n",
      "Hamming Loss: 0.206866197183\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python2.7/dist-packages/sklearn/metrics/classification.py:1074: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in samples with no predicted labels.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "print 'Chosen number of trees, depth:', best_trees, ',', best_depth\n",
    "print 'Test F1 Score:', f1_score(test_y, model_mml.predict(test_x), average='samples')\n",
    "print 'Hamming Loss:', hamming_loss(test_y, model_mml.predict(test_x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Merge the predictions back into our pickled dataset for future use.\n",
    "with open('full_dataset.pickle', 'rb') as handle:\n",
    "    dataset = pickle.load(handle)\n",
    "    \n",
    "dataset['Metadata_Train_Probabilities'] = model_mml.predict_proba(train_x)\n",
    "dataset['Metadata_Test_Probabilities'] = model_mml.predict_proba(test_x)\n",
    "\n",
    "with open('full_dataset.pickle', 'wb') as handle:\n",
    "    pickle.dump(dataset, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
