{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS 109B Advanced Topics in Data Science, Final Project, Milestone 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Group 9 - Steve Robbins, Chad Tsang, and Ted Heuer\n",
    "**Harvard University**<br>\n",
    "**Spring 2017**<br>\n",
    "**Due Date: ** Wednesday, April 12th, 2017 at 11:59pm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Milestone 4: Deep learning, due Wednesday, April 26, 2017\n",
    "\n",
    "For this milestone you will (finally) use deep learning to predict movie genres. You will train one small network from scratch on the posters only, and compare this one to a pre-trained network that you fine tune. [Here](https://keras.io/getting-started/faq/#how-can-i-use-pre-trained-models-in-keras) is a description of how to use pretrained models in Keras.\n",
    "\n",
    "You can try different architectures, initializations, parameter settings, optimization methods, etc. Be adventurous and explore deep learning! It can be fun to combine the features learned by the deep learning model with a SVM, or incorporate meta data into your deep learning model. \n",
    "\n",
    "**Note:** Be mindful of the longer training times for deep models. Not only for training time, but also for the parameter tuning efforts. You need time to develop a feel for the different parameters and which settings work, which normalization you want to use, which model architecture you choose, etc. \n",
    "\n",
    "It is great that we have GPUs via AWS to speed up the actual computation time, but you need to be mindful of your AWS credits. The GPU instances are not cheap and can accumulate costs rather quickly. Think about your model first and do some quick dry runs with a larger learning rate or large batch size on your local machine. \n",
    "\n",
    "The notebook to submit this week should at least include:\n",
    "\n",
    "- Complete description of the deep network you trained from scratch, including parameter settings, performance, features learned, etc. \n",
    "- Complete description of the pre-trained network that you fine tuned, including parameter settings, performance, features learned, etc. \n",
    "- Discussion of the results, how much improvement you gained with fine tuning, etc. \n",
    "- Discussion of at least one additional exploratory idea you pursued"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Useful links - Delete or cite these.\n",
    "https://keras.io/callbacks/\n",
    "\n",
    "https://blog.keras.io/building-powerful-image-classification-models-using-very-little-data.html\n",
    "\n",
    "https://keras.io/getting-started/faq/#how-can-i-use-keras-with-datasets-that-dont-fit-in-memory\n",
    "\n",
    "https://elitedatascience.com/keras-tutorial-deep-learning-in-python#step-4\n",
    "\n",
    "http://machinelearningmastery.com/object-recognition-convolutional-neural-networks-keras-deep-learning-library/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#!pip install keras \n",
    "#!pip install tensorflow\n",
    "#!pip install tensorflow.python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style('white')\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import misc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Conv2D, MaxPooling2D, Flatten, Dropout\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "from keras.optimizers import SGD\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load, split, and prepare the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def load_poster_data(image_size, source_size = 'w92', verbose = False):\n",
    "    # Loads the poster image data at the requested size, the assigned genre, and the movie id.\n",
    "    #\n",
    "    y_labels = pd.read_csv('y_labels_multiclass.csv')\n",
    "    image_path = './posters/' + source_size + '/'\n",
    "    posters = pd.DataFrame()\n",
    "    for movie in y_labels.iterrows():\n",
    "        row = movie[0]\n",
    "        movie_id = movie[1]['movie_id']\n",
    "        genre_id = int(movie[1]['genre_id'].replace('[', '').replace(']',''))\n",
    "        try:\n",
    "            image = misc.imread(image_path + str(movie_id) + '.jpg')\n",
    "            image_resize = img_to_array(misc.imresize(image, image_size))\n",
    "            if (image_resize.shape[2]==3):\n",
    "                posters = posters.append({'movie_id' : movie_id, \n",
    "                                          'genre_id' : genre_id,\n",
    "                                          'poster' : image_resize}, ignore_index = True)\n",
    "        except IOError:\n",
    "            if (verbose == True):\n",
    "                print('Unable to load poster for movie #', movie_id)\n",
    "    print('Loaded ', posters.shape[0], ' posters.')\n",
    "    return posters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def stratified_sampler(dataset, observations):\n",
    "    # Performs a stratified sample on the dataset and returns the number of observations \n",
    "    # requested.\n",
    "    #\n",
    "    # Parameters:\n",
    "    #    dataset:  The dataframe to sample, observing class relationships.\n",
    "    #    observations:  The number of total target observations across all classes.\n",
    "    #\n",
    "    # Returns:\n",
    "    #    A pandas dataframe sampled from the dataset maintaining class relationships.\n",
    "    class_weights = dataset.groupby(\"genre_id\").agg(['count'])/len(dataset)\n",
    "    class_sample_counts = class_weights * observations\n",
    "    class_count = class_weights.shape[0]\n",
    "    sampled = pd.DataFrame()\n",
    "    for class_to_sample in class_sample_counts.iterrows():\n",
    "        class_name = class_to_sample[0]\n",
    "        desired_class_observations = class_to_sample[1][0]\n",
    "        sampled_obs = dataset[dataset[\"genre_id\"]==class_name].sample(int(desired_class_observations), replace=\"True\")\n",
    "        sampled = sampled.append(sampled_obs, ignore_index=True)\n",
    "    return sampled, class_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def reshape_and_normalize(data):\n",
    "    image_count = data.shape[0]\n",
    "    temp = np.ndarray(shape=(image_count, data[0].shape[0], data[0].shape[1], 3))\n",
    "\n",
    "    for index in range(0, image_count):\n",
    "        try:\n",
    "            temp[index] = data[index].reshape(data[0].shape[0], data[0].shape[1], 3)\n",
    "        except ValueError:\n",
    "            print(data[index].shape)\n",
    "    temp = temp.astype('float32')\n",
    "    temp /= 255.0\n",
    "\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def normalize_responses(data):\n",
    "    unique_responses = np.sort(data[\"genre_id\"].unique())\n",
    "    data[\"genre_id\"] = data[\"genre_id\"].replace(unique_responses, range(0,len(unique_responses)), inplace=False)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def load_split_prepare_data(train_observations, test_observations, image_size, sample = 'stratified'):\n",
    "    # Loads, splits, and prepares the data for use by a CNN model.\n",
    "    #\n",
    "    # Parameters:\n",
    "    #    train_observations:  The dataframe to sample, observing class relationships.\n",
    "    #    test_observations:  The number of total target observations across all classes.\n",
    "    #    sample:  The sampling method, currently only supports 'stratified'\n",
    "    #\n",
    "    # Returns:\n",
    "    #    Nothing.\n",
    "    posters_data = load_poster_data(image_size)\n",
    "    posters = normalize_responses(posters_data)\n",
    "    \n",
    "    if (sample == 'stratified'):\n",
    "        train_sample, class_count_train = stratified_sampler(posters, train_observations)\n",
    "        test_sample, class_count_test = stratified_sampler(posters, test_observations)\n",
    "    else:\n",
    "        raise('Unsupported sample method : ', sample)\n",
    "         \n",
    "    x_train = train_sample[\"poster\"]\n",
    "    y_train = train_sample[\"genre_id\"]\n",
    "    x_test = test_sample[\"poster\"]\n",
    "    y_test = test_sample[\"genre_id\"]\n",
    "\n",
    "    img_rows = x_train[0].shape[0]\n",
    "    img_cols = x_train[0].shape[1]\n",
    "    print('Classes : ', class_count_train)\n",
    "        \n",
    "    x_train = reshape_and_normalize(x_train)\n",
    "    x_test = reshape_and_normalize(x_test)\n",
    "\n",
    "    print('x_train shape:', x_train.shape)\n",
    "    print(x_train.shape[0], 'train samples')\n",
    "    print(x_test.shape[0], 'test samples')\n",
    "    \n",
    "    # Convert response to one hot encoding\n",
    "    y_train = keras.utils.to_categorical(y_train, class_count_train)\n",
    "    y_test = keras.utils.to_categorical(y_test, class_count_test)\n",
    "\n",
    "    return (x_train, y_train), (x_test, y_test), class_count_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded  3927  posters.\n",
      "Classes :  7\n",
      "x_train shape: (4996, 138, 92, 3)\n",
      "4996 train samples\n",
      "997 test samples\n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test), classes = load_split_prepare_data(train_observations = 5000, \n",
    "                                                                        test_observations = 1000, \n",
    "                                                                        image_size = (138,92), \n",
    "                                                                        sample='stratified')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the Convolutional Neural Net architecture, from scratch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classes = 7\n",
    "final_activation_function = 'softmax'\n",
    "\n",
    "input_activation_function = 'relu'\n",
    "input_kernel_size = (5,5)\n",
    "input_shape = (138, 92, 3)\n",
    "pool_size = (3,3)\n",
    "\n",
    "hidden_activation_function = 'relu'\n",
    "hidden_kernel_size = (3,3)\n",
    "\n",
    "loss_method = 'categorical_crossentropy'\n",
    "optimizer = SGD(lr=0.1, momentum=0.9)\n",
    "eval_metric = 'accuracy'\n",
    "\n",
    "# smaller batch size means noisier gradient, but more updates per epoch\n",
    "batch_size = 256\n",
    "# number of iterations over the complete training data\n",
    "epochs = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 134, 88, 16)       1216      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 44, 29, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 42, 27, 32)        4640      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 42, 27, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 14, 9, 32)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 4032)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                258112    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 7)                 455       \n",
      "=================================================================\n",
      "Total params: 264,423\n",
      "Trainable params: 264,423\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# create an empty network model\n",
    "model = Sequential()\n",
    "\n",
    "# Input Layer\n",
    "model.add(Conv2D(16, kernel_size=input_kernel_size, activation=input_activation_function, input_shape=input_shape))\n",
    "model.add(MaxPooling2D(pool_size=pool_size))\n",
    "\n",
    "# Hidden Layer(s)\n",
    "model.add(Conv2D(32, kernel_size=hidden_kernel_size, activation=hidden_activation_function))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(MaxPooling2D(pool_size=pool_size))\n",
    "\n",
    "# Adding another layer did not improve performance, perhaps because of the pooling on pooling.\n",
    "#model.add(Conv2D(48, kernel_size=hidden_kernel_size, activation=hidden_activation_function))\n",
    "#model.add(Dropout(0.25))\n",
    "#model.add(MaxPooling2D(pool_size=pool_size))\n",
    "\n",
    "# Classification layer\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64, activation=hidden_activation_function))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(classes, activation=final_activation_function))\n",
    "\n",
    "# Display the CNN.\n",
    "model.summary()\n",
    "\n",
    "# Compile the model.\n",
    "model.compile(loss=loss_method, optimizer=optimizer, metrics=[eval_metric])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the CNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4246 samples, validate on 750 samples\n",
      "Epoch 1/200\n",
      "4246/4246 [==============================] - 47s - loss: 1.6710 - acc: 0.2862 - val_loss: 4.6371 - val_acc: 0.0000e+00\n",
      "Epoch 2/200\n",
      "4246/4246 [==============================] - 46s - loss: 1.5130 - acc: 0.3754 - val_loss: 5.0491 - val_acc: 0.0000e+00\n",
      "Epoch 3/200\n",
      "4246/4246 [==============================] - 45s - loss: 1.5057 - acc: 0.3620 - val_loss: 5.2226 - val_acc: 0.0000e+00\n",
      "Epoch 4/200\n",
      "4246/4246 [==============================] - 45s - loss: 1.4251 - acc: 0.4091 - val_loss: 6.1261 - val_acc: 0.0000e+00\n",
      "Epoch 5/200\n",
      "4246/4246 [==============================] - 44s - loss: 1.3611 - acc: 0.4277 - val_loss: 5.1586 - val_acc: 0.0000e+00\n",
      "Epoch 6/200\n",
      "4246/4246 [==============================] - 44s - loss: 1.3344 - acc: 0.4477 - val_loss: 6.5343 - val_acc: 0.0000e+00\n",
      "Epoch 7/200\n",
      "4246/4246 [==============================] - 44s - loss: 1.2504 - acc: 0.4873 - val_loss: 7.3032 - val_acc: 0.0000e+00\n",
      "Epoch 8/200\n",
      "4246/4246 [==============================] - 56s - loss: 1.2112 - acc: 0.5064 - val_loss: 6.5253 - val_acc: 0.0000e+00\n",
      "Epoch 9/200\n",
      "4246/4246 [==============================] - 45s - loss: 1.1159 - acc: 0.5518 - val_loss: 7.9559 - val_acc: 0.0000e+00\n",
      "Epoch 10/200\n",
      "4246/4246 [==============================] - 44s - loss: 1.0848 - acc: 0.5584 - val_loss: 6.8345 - val_acc: 0.0027\n",
      "Epoch 11/200\n",
      "4246/4246 [==============================] - 44s - loss: 0.9796 - acc: 0.6102 - val_loss: 7.7287 - val_acc: 0.0027\n",
      "Epoch 12/200\n",
      "4246/4246 [==============================] - 46s - loss: 0.9342 - acc: 0.6361 - val_loss: 7.2427 - val_acc: 0.0027\n",
      "Epoch 13/200\n",
      "4246/4246 [==============================] - 44s - loss: 0.9048 - acc: 0.6491 - val_loss: 8.9474 - val_acc: 0.0027\n",
      "Epoch 14/200\n",
      "4246/4246 [==============================] - 45s - loss: 0.7865 - acc: 0.6879 - val_loss: 8.7438 - val_acc: 0.0027\n",
      "Epoch 15/200\n",
      "4246/4246 [==============================] - 44s - loss: 0.7528 - acc: 0.7101 - val_loss: 9.4689 - val_acc: 0.0027\n",
      "Epoch 16/200\n",
      "4246/4246 [==============================] - 44s - loss: 0.7236 - acc: 0.7176 - val_loss: 9.4193 - val_acc: 0.0027\n",
      "Epoch 17/200\n",
      "4246/4246 [==============================] - 44s - loss: 0.7101 - acc: 0.7204 - val_loss: 10.2099 - val_acc: 0.0027\n",
      "Epoch 18/200\n",
      "4246/4246 [==============================] - 44s - loss: 0.6340 - acc: 0.7492 - val_loss: 8.9104 - val_acc: 0.0027\n",
      "Epoch 19/200\n",
      "4246/4246 [==============================] - 44s - loss: 0.6251 - acc: 0.7602 - val_loss: 8.5795 - val_acc: 0.0027\n",
      "Epoch 20/200\n",
      "4246/4246 [==============================] - 45s - loss: 0.5736 - acc: 0.7715 - val_loss: 10.4932 - val_acc: 0.0027\n",
      "Epoch 21/200\n",
      "4246/4246 [==============================] - 44s - loss: 0.5707 - acc: 0.7810 - val_loss: 9.7364 - val_acc: 0.0027\n",
      "Epoch 22/200\n",
      "4246/4246 [==============================] - 44s - loss: 0.5609 - acc: 0.7786 - val_loss: 9.4854 - val_acc: 0.0040\n",
      "Epoch 23/200\n",
      "4246/4246 [==============================] - 44s - loss: 0.5073 - acc: 0.8038 - val_loss: 10.0042 - val_acc: 0.0040\n",
      "Epoch 24/200\n",
      "4246/4246 [==============================] - 44s - loss: 0.4871 - acc: 0.8125 - val_loss: 9.7003 - val_acc: 0.0040\n",
      "Epoch 25/200\n",
      "4246/4246 [==============================] - 44s - loss: 0.5251 - acc: 0.8003 - val_loss: 10.0434 - val_acc: 0.0040\n",
      "Epoch 26/200\n",
      "4246/4246 [==============================] - 44s - loss: 0.5005 - acc: 0.8062 - val_loss: 10.5111 - val_acc: 0.0040\n",
      "Epoch 27/200\n",
      "4246/4246 [==============================] - 44s - loss: 0.4437 - acc: 0.8269 - val_loss: 10.9676 - val_acc: 0.0040\n",
      "Epoch 28/200\n",
      "4246/4246 [==============================] - 44s - loss: 0.4717 - acc: 0.8123 - val_loss: 10.4518 - val_acc: 0.0040\n",
      "Epoch 29/200\n",
      "4246/4246 [==============================] - 44s - loss: 0.4121 - acc: 0.8453 - val_loss: 11.1354 - val_acc: 0.0040\n",
      "Epoch 30/200\n",
      "4246/4246 [==============================] - 44s - loss: 0.4238 - acc: 0.8446 - val_loss: 10.9979 - val_acc: 0.0040\n",
      "Epoch 31/200\n",
      "4246/4246 [==============================] - 44s - loss: 0.4029 - acc: 0.8431 - val_loss: 11.1972 - val_acc: 0.0040\n",
      "Epoch 32/200\n",
      "4246/4246 [==============================] - 44s - loss: 0.3974 - acc: 0.8431 - val_loss: 10.9410 - val_acc: 0.0040\n",
      "Epoch 33/200\n",
      "4246/4246 [==============================] - 54s - loss: 0.4097 - acc: 0.8436 - val_loss: 11.2344 - val_acc: 0.0040\n",
      "Epoch 34/200\n",
      "4246/4246 [==============================] - 59s - loss: 0.3995 - acc: 0.8469 - val_loss: 10.6216 - val_acc: 0.0040\n",
      "Epoch 35/200\n",
      "4246/4246 [==============================] - 59s - loss: 0.3725 - acc: 0.8585 - val_loss: 11.3429 - val_acc: 0.0040\n",
      "Epoch 36/200\n",
      "4246/4246 [==============================] - 59s - loss: 0.4319 - acc: 0.8391 - val_loss: 10.5825 - val_acc: 0.0027\n",
      "Epoch 37/200\n",
      "4246/4246 [==============================] - 60s - loss: 0.4185 - acc: 0.8398 - val_loss: 11.2579 - val_acc: 0.0040\n",
      "Epoch 38/200\n",
      "4246/4246 [==============================] - 60s - loss: 0.3522 - acc: 0.8669 - val_loss: 11.1940 - val_acc: 0.0040\n",
      "Epoch 39/200\n",
      "4246/4246 [==============================] - 60s - loss: 0.3442 - acc: 0.8683 - val_loss: 11.6164 - val_acc: 0.0040\n",
      "Epoch 40/200\n",
      "4246/4246 [==============================] - 59s - loss: 0.3385 - acc: 0.8683 - val_loss: 11.4355 - val_acc: 0.0040\n",
      "Epoch 41/200\n",
      "4246/4246 [==============================] - 59s - loss: 0.3013 - acc: 0.8853 - val_loss: 12.0043 - val_acc: 0.0040\n",
      "Epoch 42/200\n",
      "4246/4246 [==============================] - 60s - loss: 0.3229 - acc: 0.8764 - val_loss: 11.1187 - val_acc: 0.0040\n",
      "Epoch 43/200\n",
      "4246/4246 [==============================] - 60s - loss: 0.2954 - acc: 0.8914 - val_loss: 11.6937 - val_acc: 0.0040\n",
      "Epoch 44/200\n",
      "4246/4246 [==============================] - 60s - loss: 0.3018 - acc: 0.8935 - val_loss: 11.9744 - val_acc: 0.0040\n",
      "Epoch 45/200\n",
      "4246/4246 [==============================] - 61s - loss: 0.2865 - acc: 0.8900 - val_loss: 12.6906 - val_acc: 0.0040\n",
      "Epoch 46/200\n",
      "4246/4246 [==============================] - 45s - loss: 0.3057 - acc: 0.8898 - val_loss: 11.9069 - val_acc: 0.0040\n",
      "Epoch 47/200\n",
      "4246/4246 [==============================] - 45s - loss: 0.3061 - acc: 0.8820 - val_loss: 11.7134 - val_acc: 0.0040\n",
      "Epoch 48/200\n",
      "4246/4246 [==============================] - 44s - loss: 0.3177 - acc: 0.8797 - val_loss: 11.2174 - val_acc: 0.0040\n",
      "Epoch 49/200\n",
      "4246/4246 [==============================] - 49s - loss: 0.2917 - acc: 0.8855 - val_loss: 11.6810 - val_acc: 0.0040\n",
      "Epoch 50/200\n",
      "4246/4246 [==============================] - 45s - loss: 0.3036 - acc: 0.8900 - val_loss: 11.4748 - val_acc: 0.0027\n",
      "Epoch 51/200\n",
      "4246/4246 [==============================] - 44s - loss: 0.3811 - acc: 0.8662 - val_loss: 10.8608 - val_acc: 0.0040\n",
      "Epoch 52/200\n",
      "4246/4246 [==============================] - 45s - loss: 0.3372 - acc: 0.8756 - val_loss: 12.1870 - val_acc: 0.0040\n",
      "Epoch 53/200\n",
      "4246/4246 [==============================] - 44s - loss: 0.3288 - acc: 0.8792 - val_loss: 11.0298 - val_acc: 0.0040\n",
      "Epoch 54/200\n",
      "4246/4246 [==============================] - 44s - loss: 0.3326 - acc: 0.8818 - val_loss: 12.0230 - val_acc: 0.0040\n",
      "Epoch 55/200\n",
      "4246/4246 [==============================] - 45s - loss: 0.3301 - acc: 0.8825 - val_loss: 11.7192 - val_acc: 0.0040\n",
      "Epoch 56/200\n",
      "4246/4246 [==============================] - 45s - loss: 0.3378 - acc: 0.8768 - val_loss: 12.0165 - val_acc: 0.0040\n",
      "Epoch 57/200\n",
      "4246/4246 [==============================] - 44s - loss: 0.3413 - acc: 0.8700 - val_loss: 11.6368 - val_acc: 0.0040\n",
      "Epoch 58/200\n",
      "4246/4246 [==============================] - 44s - loss: 0.3296 - acc: 0.8825 - val_loss: 11.3493 - val_acc: 0.0040\n",
      "Epoch 59/200\n",
      "4246/4246 [==============================] - 44s - loss: 0.2932 - acc: 0.8895 - val_loss: 12.0953 - val_acc: 0.0040\n",
      "Epoch 60/200\n",
      "4246/4246 [==============================] - 44s - loss: 0.2700 - acc: 0.9056 - val_loss: 12.2489 - val_acc: 0.0040\n",
      "Epoch 61/200\n",
      "4246/4246 [==============================] - 44s - loss: 0.2678 - acc: 0.8961 - val_loss: 12.2971 - val_acc: 0.0040\n",
      "Epoch 62/200\n",
      "4246/4246 [==============================] - 44s - loss: 0.2621 - acc: 0.9079 - val_loss: 12.5112 - val_acc: 0.0040\n",
      "Epoch 63/200\n",
      "4246/4246 [==============================] - 44s - loss: 0.2518 - acc: 0.9098 - val_loss: 12.2629 - val_acc: 0.0040\n",
      "Epoch 64/200\n",
      "4246/4246 [==============================] - 44s - loss: 0.2706 - acc: 0.8990 - val_loss: 12.2297 - val_acc: 0.0040\n",
      "Epoch 65/200\n",
      "4246/4246 [==============================] - 44s - loss: 0.2614 - acc: 0.9027 - val_loss: 12.8417 - val_acc: 0.0040\n",
      "Epoch 66/200\n",
      "4246/4246 [==============================] - 44s - loss: 0.2817 - acc: 0.8992 - val_loss: 12.2339 - val_acc: 0.0040\n",
      "Epoch 67/200\n",
      "4246/4246 [==============================] - 44s - loss: 0.2560 - acc: 0.9072 - val_loss: 12.8021 - val_acc: 0.0040\n",
      "Epoch 68/200\n",
      "4246/4246 [==============================] - 44s - loss: 0.2297 - acc: 0.9117 - val_loss: 12.1166 - val_acc: 0.0040\n",
      "Epoch 69/200\n",
      "4246/4246 [==============================] - 48s - loss: 0.2661 - acc: 0.9037 - val_loss: 13.2321 - val_acc: 0.0040\n",
      "Epoch 70/200\n",
      "4246/4246 [==============================] - 60s - loss: 0.2584 - acc: 0.8997 - val_loss: 12.6750 - val_acc: 0.0040\n",
      "Epoch 71/200\n",
      "4246/4246 [==============================] - 56s - loss: 0.2512 - acc: 0.9117 - val_loss: 11.7750 - val_acc: 0.0040\n",
      "Epoch 72/200\n",
      "4246/4246 [==============================] - 45s - loss: 0.2394 - acc: 0.9093 - val_loss: 12.8502 - val_acc: 0.0040\n",
      "Epoch 73/200\n",
      "4246/4246 [==============================] - 45s - loss: 0.2410 - acc: 0.9107 - val_loss: 13.4109 - val_acc: 0.0040\n",
      "Epoch 74/200\n",
      "4246/4246 [==============================] - 45s - loss: 0.2356 - acc: 0.9166 - val_loss: 12.7059 - val_acc: 0.0040\n",
      "Epoch 75/200\n",
      "4246/4246 [==============================] - 44s - loss: 0.2314 - acc: 0.9140 - val_loss: 12.7776 - val_acc: 0.0040\n",
      "Epoch 76/200\n",
      "4246/4246 [==============================] - 45s - loss: 0.2242 - acc: 0.9152 - val_loss: 12.6299 - val_acc: 0.0040\n",
      "Epoch 77/200\n",
      "4246/4246 [==============================] - 44s - loss: 0.2215 - acc: 0.9145 - val_loss: 12.2041 - val_acc: 0.0040\n",
      "Epoch 78/200\n",
      "4246/4246 [==============================] - 44s - loss: 0.2196 - acc: 0.9164 - val_loss: 12.6971 - val_acc: 0.0040\n",
      "Epoch 79/200\n",
      "4246/4246 [==============================] - 45s - loss: 0.2353 - acc: 0.9154 - val_loss: 12.6411 - val_acc: 0.0040\n",
      "Epoch 80/200\n",
      "4246/4246 [==============================] - 45s - loss: 0.1930 - acc: 0.9249 - val_loss: 13.3623 - val_acc: 0.0040\n",
      "Epoch 81/200\n",
      "4246/4246 [==============================] - 44s - loss: 0.2107 - acc: 0.9251 - val_loss: 13.0792 - val_acc: 0.0040\n",
      "Epoch 82/200\n",
      "4246/4246 [==============================] - 44s - loss: 0.2129 - acc: 0.9218 - val_loss: 12.8987 - val_acc: 0.0040\n",
      "Epoch 83/200\n",
      "4246/4246 [==============================] - 44s - loss: 0.2308 - acc: 0.9187 - val_loss: 12.4309 - val_acc: 0.0040\n",
      "Epoch 84/200\n",
      "4246/4246 [==============================] - 44s - loss: 0.2027 - acc: 0.9260 - val_loss: 12.6275 - val_acc: 0.0040\n",
      "Epoch 85/200\n",
      "4246/4246 [==============================] - 44s - loss: 0.1864 - acc: 0.9277 - val_loss: 12.8949 - val_acc: 0.0040\n",
      "Epoch 86/200\n",
      "4246/4246 [==============================] - 44s - loss: 0.1895 - acc: 0.9253 - val_loss: 12.2721 - val_acc: 0.0040\n",
      "Epoch 87/200\n",
      "4246/4246 [==============================] - 44s - loss: 0.1840 - acc: 0.9315 - val_loss: 12.9904 - val_acc: 0.0040\n",
      "Epoch 88/200\n",
      "4246/4246 [==============================] - 44s - loss: 0.2029 - acc: 0.9270 - val_loss: 12.7734 - val_acc: 0.0040\n",
      "Epoch 89/200\n",
      "4246/4246 [==============================] - 44s - loss: 0.1979 - acc: 0.9301 - val_loss: 12.7993 - val_acc: 0.0040\n",
      "Epoch 90/200\n",
      "4246/4246 [==============================] - 44s - loss: 0.2235 - acc: 0.9162 - val_loss: 12.5941 - val_acc: 0.0040\n",
      "Epoch 91/200\n",
      "4246/4246 [==============================] - 44s - loss: 0.2290 - acc: 0.9145 - val_loss: 12.6945 - val_acc: 0.0040\n",
      "Epoch 92/200\n",
      "4246/4246 [==============================] - 44s - loss: 0.2283 - acc: 0.9133 - val_loss: 13.0672 - val_acc: 0.0040\n",
      "Epoch 93/200\n",
      "4246/4246 [==============================] - 52s - loss: 0.2113 - acc: 0.9235 - val_loss: 12.8667 - val_acc: 0.0040\n",
      "Epoch 94/200\n",
      "4246/4246 [==============================] - 60s - loss: 0.1991 - acc: 0.9249 - val_loss: 12.8848 - val_acc: 0.0040\n",
      "Epoch 95/200\n",
      "4246/4246 [==============================] - 59s - loss: 0.1932 - acc: 0.9293 - val_loss: 13.1671 - val_acc: 0.0040\n",
      "Epoch 96/200\n",
      "4246/4246 [==============================] - 59s - loss: 0.2083 - acc: 0.9230 - val_loss: 12.6045 - val_acc: 0.0040\n",
      "Epoch 97/200\n",
      "4246/4246 [==============================] - 55s - loss: 0.1877 - acc: 0.9265 - val_loss: 13.4139 - val_acc: 0.0040\n",
      "Epoch 98/200\n",
      "4246/4246 [==============================] - 44s - loss: 0.1960 - acc: 0.9296 - val_loss: 13.2053 - val_acc: 0.0040\n",
      "Epoch 99/200\n",
      "4246/4246 [==============================] - 44s - loss: 0.2119 - acc: 0.9289 - val_loss: 12.9562 - val_acc: 0.0040\n",
      "Epoch 100/200\n",
      "4246/4246 [==============================] - 44s - loss: 0.2044 - acc: 0.9216 - val_loss: 12.9639 - val_acc: 0.0040\n",
      "Epoch 101/200\n",
      "4246/4246 [==============================] - 44s - loss: 0.2065 - acc: 0.9246 - val_loss: 13.5264 - val_acc: 0.0040\n",
      "Epoch 102/200\n",
      "4246/4246 [==============================] - 44s - loss: 0.1963 - acc: 0.9291 - val_loss: 12.7412 - val_acc: 0.0040\n",
      "Epoch 103/200\n",
      "4246/4246 [==============================] - 44s - loss: 0.1906 - acc: 0.9284 - val_loss: 13.1028 - val_acc: 0.0040\n",
      "Epoch 104/200\n",
      "4246/4246 [==============================] - 45s - loss: 0.1943 - acc: 0.9275 - val_loss: 12.9800 - val_acc: 0.0040\n",
      "Epoch 105/200\n",
      "4246/4246 [==============================] - 44s - loss: 0.2157 - acc: 0.9277 - val_loss: 12.8832 - val_acc: 0.0040\n",
      "Epoch 106/200\n",
      "4246/4246 [==============================] - 45s - loss: 0.1821 - acc: 0.9329 - val_loss: 13.4537 - val_acc: 0.0040\n",
      "Epoch 107/200\n",
      "4246/4246 [==============================] - 45s - loss: 0.1886 - acc: 0.9331 - val_loss: 13.8108 - val_acc: 0.0040\n",
      "Epoch 108/200\n",
      "4246/4246 [==============================] - 45s - loss: 0.1999 - acc: 0.9253 - val_loss: 13.1344 - val_acc: 0.0040\n",
      "Epoch 109/200\n",
      "4246/4246 [==============================] - 45s - loss: 0.1891 - acc: 0.9310 - val_loss: 13.1719 - val_acc: 0.0040\n",
      "Epoch 110/200\n",
      "4246/4246 [==============================] - 44s - loss: 0.1828 - acc: 0.9338 - val_loss: 13.4088 - val_acc: 0.0040\n",
      "Epoch 111/200\n",
      "4246/4246 [==============================] - 45s - loss: 0.1787 - acc: 0.9338 - val_loss: 13.7539 - val_acc: 0.0040\n",
      "Epoch 112/200\n",
      "4246/4246 [==============================] - 44s - loss: 0.2069 - acc: 0.9242 - val_loss: 13.5672 - val_acc: 0.0040\n",
      "Epoch 113/200\n",
      "4246/4246 [==============================] - 44s - loss: 0.2474 - acc: 0.9126 - val_loss: 13.7038 - val_acc: 0.0040\n",
      "Epoch 114/200\n",
      "4246/4246 [==============================] - 45s - loss: 0.2302 - acc: 0.9180 - val_loss: 13.1367 - val_acc: 0.0040\n",
      "Epoch 115/200\n",
      "4246/4246 [==============================] - 45s - loss: 0.2096 - acc: 0.9251 - val_loss: 14.0567 - val_acc: 0.0040\n",
      "Epoch 116/200\n",
      "4246/4246 [==============================] - 44s - loss: 0.2449 - acc: 0.9143 - val_loss: 13.5358 - val_acc: 0.0040\n",
      "Epoch 117/200\n",
      "4246/4246 [==============================] - 45s - loss: 0.2259 - acc: 0.9242 - val_loss: 12.8558 - val_acc: 0.0040\n",
      "Epoch 118/200\n",
      "4246/4246 [==============================] - 44s - loss: 0.2271 - acc: 0.9213 - val_loss: 13.6615 - val_acc: 0.0040\n",
      "Epoch 119/200\n",
      "4246/4246 [==============================] - 45s - loss: 0.2195 - acc: 0.9263 - val_loss: 13.8172 - val_acc: 0.0040\n",
      "Epoch 120/200\n",
      "4246/4246 [==============================] - 44s - loss: 0.2404 - acc: 0.9159 - val_loss: 13.4314 - val_acc: 0.0040\n",
      "Epoch 121/200\n",
      "4246/4246 [==============================] - 44s - loss: 0.2324 - acc: 0.9159 - val_loss: 12.3543 - val_acc: 0.0040\n",
      "Epoch 122/200\n",
      "4246/4246 [==============================] - 45s - loss: 0.2125 - acc: 0.9251 - val_loss: 13.6833 - val_acc: 0.0040\n",
      "Epoch 123/200\n",
      "4246/4246 [==============================] - 44s - loss: 0.2128 - acc: 0.9277 - val_loss: 12.7799 - val_acc: 0.0040\n",
      "Epoch 124/200\n",
      "4246/4246 [==============================] - 45s - loss: 0.1805 - acc: 0.9359 - val_loss: 13.4503 - val_acc: 0.0040\n",
      "Epoch 125/200\n",
      "4246/4246 [==============================] - 44s - loss: 0.1616 - acc: 0.9409 - val_loss: 13.7282 - val_acc: 0.0040\n",
      "Epoch 126/200\n",
      "4246/4246 [==============================] - 44s - loss: 0.1918 - acc: 0.9305 - val_loss: 13.4122 - val_acc: 0.0040\n",
      "Epoch 127/200\n",
      "4246/4246 [==============================] - 45s - loss: 0.2087 - acc: 0.9279 - val_loss: 13.4782 - val_acc: 0.0040\n",
      "Epoch 128/200\n",
      "4246/4246 [==============================] - 44s - loss: 0.1942 - acc: 0.9286 - val_loss: 13.4460 - val_acc: 0.0040\n",
      "Epoch 129/200\n",
      "4246/4246 [==============================] - 44s - loss: 0.1734 - acc: 0.9376 - val_loss: 13.0497 - val_acc: 0.0040\n",
      "Epoch 130/200\n",
      "4246/4246 [==============================] - 44s - loss: 0.1704 - acc: 0.9333 - val_loss: 13.2315 - val_acc: 0.0040\n",
      "Epoch 131/200\n",
      "4246/4246 [==============================] - 44s - loss: 0.1680 - acc: 0.9423 - val_loss: 13.5823 - val_acc: 0.0040\n",
      "Epoch 132/200\n",
      "4246/4246 [==============================] - 45s - loss: 0.1830 - acc: 0.9397 - val_loss: 13.2156 - val_acc: 0.0040\n",
      "Epoch 133/200\n",
      "4246/4246 [==============================] - 44s - loss: 0.1634 - acc: 0.9388 - val_loss: 13.6106 - val_acc: 0.0040\n",
      "Epoch 134/200\n",
      "4246/4246 [==============================] - 44s - loss: 0.1785 - acc: 0.9341 - val_loss: 13.2226 - val_acc: 0.0040\n",
      "Epoch 135/200\n",
      "4246/4246 [==============================] - 53s - loss: 0.1987 - acc: 0.9296 - val_loss: 13.3125 - val_acc: 0.0040\n",
      "Epoch 136/200\n",
      "4246/4246 [==============================] - 48s - loss: 0.2048 - acc: 0.9284 - val_loss: 13.7306 - val_acc: 0.0040\n",
      "Epoch 137/200\n",
      "4246/4246 [==============================] - 46s - loss: 0.2075 - acc: 0.9291 - val_loss: 13.5517 - val_acc: 0.0040\n",
      "Epoch 138/200\n",
      "4246/4246 [==============================] - 45s - loss: 0.2140 - acc: 0.9251 - val_loss: 13.2981 - val_acc: 0.0040\n",
      "Epoch 139/200\n",
      "4246/4246 [==============================] - 55s - loss: 0.1893 - acc: 0.9317 - val_loss: 13.8361 - val_acc: 0.0040\n",
      "Epoch 140/200\n",
      "4246/4246 [==============================] - 59s - loss: 0.1875 - acc: 0.9312 - val_loss: 13.9544 - val_acc: 0.0040\n",
      "Epoch 141/200\n",
      "4246/4246 [==============================] - 47s - loss: 0.2362 - acc: 0.9199 - val_loss: 13.9678 - val_acc: 0.0040\n",
      "Epoch 142/200\n",
      "4246/4246 [==============================] - 45s - loss: 0.2675 - acc: 0.9143 - val_loss: 13.1743 - val_acc: 0.0040\n",
      "Epoch 143/200\n",
      "4246/4246 [==============================] - 45s - loss: 0.2488 - acc: 0.9176 - val_loss: 13.6088 - val_acc: 0.0040\n",
      "Epoch 144/200\n",
      "4246/4246 [==============================] - 44s - loss: 0.2318 - acc: 0.9242 - val_loss: 12.9521 - val_acc: 0.0040\n",
      "Epoch 145/200\n",
      "4246/4246 [==============================] - 45s - loss: 0.1978 - acc: 0.9272 - val_loss: 13.4642 - val_acc: 0.0040\n",
      "Epoch 146/200\n",
      "4246/4246 [==============================] - 44s - loss: 0.1893 - acc: 0.9310 - val_loss: 13.9217 - val_acc: 0.0040\n",
      "Epoch 147/200\n",
      "4246/4246 [==============================] - 45s - loss: 0.2072 - acc: 0.9268 - val_loss: 13.8722 - val_acc: 0.0040\n",
      "Epoch 148/200\n",
      "4246/4246 [==============================] - 45s - loss: 0.1995 - acc: 0.9303 - val_loss: 13.4619 - val_acc: 0.0040\n",
      "Epoch 149/200\n",
      "4246/4246 [==============================] - 44s - loss: 0.2216 - acc: 0.9251 - val_loss: 13.1532 - val_acc: 0.0040\n",
      "Epoch 150/200\n",
      "4246/4246 [==============================] - 45s - loss: 0.1922 - acc: 0.9343 - val_loss: 13.2316 - val_acc: 0.0040\n",
      "Epoch 151/200\n",
      "4246/4246 [==============================] - 45s - loss: 0.2096 - acc: 0.9277 - val_loss: 12.8857 - val_acc: 0.0040\n",
      "Epoch 152/200\n",
      "4246/4246 [==============================] - 45s - loss: 0.1989 - acc: 0.9317 - val_loss: 12.9082 - val_acc: 0.0040\n",
      "Epoch 153/200\n",
      "4246/4246 [==============================] - 45s - loss: 0.2447 - acc: 0.9152 - val_loss: 13.5006 - val_acc: 0.0040\n",
      "Epoch 154/200\n",
      "4246/4246 [==============================] - 44s - loss: 0.2246 - acc: 0.9171 - val_loss: 13.6756 - val_acc: 0.0040\n",
      "Epoch 155/200\n",
      "4246/4246 [==============================] - 45s - loss: 0.2474 - acc: 0.9204 - val_loss: 13.3934 - val_acc: 0.0040\n",
      "Epoch 156/200\n",
      "4246/4246 [==============================] - 44s - loss: 0.2221 - acc: 0.9244 - val_loss: 13.4131 - val_acc: 0.0040\n",
      "Epoch 157/200\n",
      "4246/4246 [==============================] - 44s - loss: 0.2270 - acc: 0.9246 - val_loss: 13.0772 - val_acc: 0.0040\n",
      "Epoch 158/200\n",
      "4246/4246 [==============================] - 44s - loss: 0.2466 - acc: 0.9154 - val_loss: 13.8114 - val_acc: 0.0040\n",
      "Epoch 159/200\n",
      "4246/4246 [==============================] - 44s - loss: 0.1993 - acc: 0.9308 - val_loss: 13.4716 - val_acc: 0.0040\n",
      "Epoch 160/200\n",
      "4246/4246 [==============================] - 45s - loss: 0.2239 - acc: 0.9242 - val_loss: 13.4147 - val_acc: 0.0040\n",
      "Epoch 161/200\n",
      "4246/4246 [==============================] - 45s - loss: 0.1706 - acc: 0.9430 - val_loss: 13.5652 - val_acc: 0.0040\n",
      "Epoch 162/200\n",
      "4246/4246 [==============================] - 44s - loss: 0.1841 - acc: 0.9352 - val_loss: 13.3766 - val_acc: 0.0040\n",
      "Epoch 163/200\n",
      "4246/4246 [==============================] - 44s - loss: 0.1955 - acc: 0.9345 - val_loss: 13.4238 - val_acc: 0.0040\n",
      "Epoch 164/200\n",
      "4246/4246 [==============================] - 44s - loss: 0.2446 - acc: 0.9176 - val_loss: 13.0276 - val_acc: 0.0040\n",
      "Epoch 165/200\n",
      "4246/4246 [==============================] - 44s - loss: 0.2388 - acc: 0.9187 - val_loss: 13.2985 - val_acc: 0.0040\n",
      "Epoch 166/200\n",
      "4246/4246 [==============================] - 53s - loss: 0.1864 - acc: 0.9308 - val_loss: 12.9563 - val_acc: 0.0040\n",
      "Epoch 167/200\n",
      "4246/4246 [==============================] - 59s - loss: 0.1662 - acc: 0.9402 - val_loss: 13.7830 - val_acc: 0.0040\n",
      "Epoch 168/200\n",
      "4246/4246 [==============================] - 59s - loss: 0.1799 - acc: 0.9397 - val_loss: 12.9115 - val_acc: 0.0040\n",
      "Epoch 169/200\n",
      "4246/4246 [==============================] - 52s - loss: 0.2017 - acc: 0.9296 - val_loss: 13.7486 - val_acc: 0.0040\n",
      "Epoch 170/200\n",
      "4246/4246 [==============================] - 44s - loss: 0.1788 - acc: 0.9381 - val_loss: 13.3689 - val_acc: 0.0040\n",
      "Epoch 171/200\n",
      "4246/4246 [==============================] - 45s - loss: 0.1694 - acc: 0.9366 - val_loss: 13.7174 - val_acc: 0.0040\n",
      "Epoch 172/200\n",
      "4246/4246 [==============================] - 45s - loss: 0.1924 - acc: 0.9402 - val_loss: 12.7722 - val_acc: 0.0040\n",
      "Epoch 173/200\n",
      "4246/4246 [==============================] - 45s - loss: 0.1708 - acc: 0.9390 - val_loss: 12.8606 - val_acc: 0.0040\n",
      "Epoch 174/200\n",
      "4246/4246 [==============================] - 44s - loss: 0.1736 - acc: 0.9418 - val_loss: 13.0740 - val_acc: 0.0040\n",
      "Epoch 175/200\n",
      "4246/4246 [==============================] - 44s - loss: 0.1681 - acc: 0.9388 - val_loss: 13.3618 - val_acc: 0.0040\n",
      "Epoch 176/200\n",
      "4246/4246 [==============================] - 44s - loss: 0.1682 - acc: 0.9371 - val_loss: 13.4039 - val_acc: 0.0040\n",
      "Epoch 177/200\n",
      "4246/4246 [==============================] - 45s - loss: 0.1404 - acc: 0.9491 - val_loss: 13.0110 - val_acc: 0.0040\n",
      "Epoch 178/200\n",
      "4246/4246 [==============================] - 45s - loss: 0.1380 - acc: 0.9480 - val_loss: 12.9493 - val_acc: 0.0040\n",
      "Epoch 179/200\n",
      "4246/4246 [==============================] - 44s - loss: 0.1504 - acc: 0.9432 - val_loss: 13.3781 - val_acc: 0.0040\n",
      "Epoch 180/200\n",
      "4246/4246 [==============================] - 46s - loss: 0.1561 - acc: 0.9454 - val_loss: 13.6741 - val_acc: 0.0040\n",
      "Epoch 181/200\n",
      "4246/4246 [==============================] - 45s - loss: 0.1399 - acc: 0.9496 - val_loss: 13.7156 - val_acc: 0.0040\n",
      "Epoch 182/200\n",
      "4246/4246 [==============================] - 45s - loss: 0.1511 - acc: 0.9468 - val_loss: 13.0304 - val_acc: 0.0040\n",
      "Epoch 183/200\n",
      "4246/4246 [==============================] - 45s - loss: 0.1478 - acc: 0.9489 - val_loss: 13.0746 - val_acc: 0.0040\n",
      "Epoch 184/200\n",
      "4246/4246 [==============================] - 45s - loss: 0.1465 - acc: 0.9494 - val_loss: 13.5700 - val_acc: 0.0040\n",
      "Epoch 185/200\n",
      "4246/4246 [==============================] - 45s - loss: 0.1540 - acc: 0.9432 - val_loss: 13.3978 - val_acc: 0.0040\n",
      "Epoch 186/200\n",
      "4246/4246 [==============================] - 44s - loss: 0.1496 - acc: 0.9489 - val_loss: 13.3530 - val_acc: 0.0040\n",
      "Epoch 187/200\n",
      "4246/4246 [==============================] - 44s - loss: 0.1850 - acc: 0.9369 - val_loss: 13.2403 - val_acc: 0.0040\n",
      "Epoch 188/200\n",
      "4246/4246 [==============================] - 45s - loss: 0.2001 - acc: 0.9348 - val_loss: 13.9368 - val_acc: 0.0040\n",
      "Epoch 189/200\n",
      "4246/4246 [==============================] - 44s - loss: 0.1895 - acc: 0.9343 - val_loss: 12.7272 - val_acc: 0.0040\n",
      "Epoch 190/200\n",
      "4246/4246 [==============================] - 44s - loss: 0.1627 - acc: 0.9442 - val_loss: 13.4972 - val_acc: 0.0040\n",
      "Epoch 191/200\n",
      "4246/4246 [==============================] - 44s - loss: 0.1661 - acc: 0.9430 - val_loss: 13.2900 - val_acc: 0.0040\n",
      "Epoch 192/200\n",
      "4246/4246 [==============================] - 45s - loss: 0.1734 - acc: 0.9378 - val_loss: 13.2184 - val_acc: 0.0040\n",
      "Epoch 193/200\n",
      "4246/4246 [==============================] - 45s - loss: 0.1786 - acc: 0.9390 - val_loss: 13.5502 - val_acc: 0.0040\n",
      "Epoch 194/200\n",
      "4246/4246 [==============================] - 44s - loss: 0.1661 - acc: 0.9418 - val_loss: 14.0641 - val_acc: 0.0040\n",
      "Epoch 195/200\n",
      "4246/4246 [==============================] - 45s - loss: 0.1730 - acc: 0.9437 - val_loss: 13.1978 - val_acc: 0.0040\n",
      "Epoch 196/200\n",
      "4246/4246 [==============================] - 45s - loss: 0.1646 - acc: 0.9390 - val_loss: 13.6658 - val_acc: 0.0040\n",
      "Epoch 197/200\n",
      "4246/4246 [==============================] - 44s - loss: 0.1641 - acc: 0.9435 - val_loss: 13.3325 - val_acc: 0.0040\n",
      "Epoch 198/200\n",
      "4246/4246 [==============================] - 44s - loss: 0.1547 - acc: 0.9465 - val_loss: 13.2462 - val_acc: 0.0040\n",
      "Epoch 199/200\n",
      "4246/4246 [==============================] - 45s - loss: 0.1362 - acc: 0.9496 - val_loss: 13.9918 - val_acc: 0.0040\n",
      "Epoch 200/200\n",
      "4246/4246 [==============================] - 44s - loss: 0.1337 - acc: 0.9510 - val_loss: 13.6339 - val_acc: 0.0040\n",
      "Test loss: 2.96140685794\n",
      "Test accuracy: 0.700100300903\n"
     ]
    }
   ],
   "source": [
    "# The actual training of the CNN using the parameters and model previously specified.\n",
    "# The validation set is a split of the stratified sampled training data.\n",
    "history = model.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_split = 0.15)\n",
    "\n",
    "# Evaluate the performance on the unused testing set.\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save_weights('tuned_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<keras.layers.convolutional.Conv2D at 0x1154fd210>,\n",
       " <keras.layers.pooling.MaxPooling2D at 0x1154fd290>,\n",
       " <keras.layers.convolutional.Conv2D at 0x103faa490>,\n",
       " <keras.layers.core.Dropout at 0x1154fd8d0>,\n",
       " <keras.layers.pooling.MaxPooling2D at 0x1154fd9d0>,\n",
       " <keras.layers.core.Flatten at 0x10402b710>,\n",
       " <keras.layers.core.Dense at 0x103fc6b90>,\n",
       " <keras.layers.core.Dropout at 0x103fc6f90>,\n",
       " <keras.layers.core.Dense at 0x104056bd0>]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfcAAAFtCAYAAAAaiCMCAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1193aadd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# here is a visualization of the training process\n",
    "# typically we gain a lot in the beginning and then\n",
    "# training slows down\n",
    "plt.plot(history.history['acc'])\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.title(\"Training Accuracy, Baseline Model\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above, we see that this model with 200 epochs (which includes some slight tuning) yielded an impressive accuracy of 70% on the unseen test set, and 95% accuracy on the training set.  Next, we will add another convultional, dropout, and pooling layer and see the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_97 (Conv2D)           (None, 134, 88, 16)       1216      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 44, 29, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_98 (Conv2D)           (None, 42, 27, 32)        4640      \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 42, 27, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 14, 9, 32)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_99 (Conv2D)           (None, 12, 7, 48)         13872     \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 12, 7, 48)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 4, 2, 48)          0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 384)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 64)                24640     \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 7)                 455       \n",
      "=================================================================\n",
      "Total params: 44,823\n",
      "Trainable params: 44,823\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# create an empty network model\n",
    "model2 = Sequential()\n",
    "\n",
    "# Input Layer\n",
    "model2.add(Conv2D(16, kernel_size=input_kernel_size, activation=input_activation_function, input_shape=input_shape))\n",
    "model2.add(MaxPooling2D(pool_size=pool_size))\n",
    "\n",
    "# Hidden Layer(s)\n",
    "model2.add(Conv2D(32, kernel_size=hidden_kernel_size, activation=hidden_activation_function))\n",
    "model2.add(Dropout(0.25))\n",
    "model2.add(MaxPooling2D(pool_size=pool_size))\n",
    "\n",
    "model2.add(Conv2D(48, kernel_size=hidden_kernel_size, activation=hidden_activation_function))\n",
    "model2.add(Dropout(0.25))\n",
    "model2.add(MaxPooling2D(pool_size=pool_size))\n",
    "\n",
    "# Classification layer\n",
    "model2.add(Flatten())\n",
    "model2.add(Dense(64, activation=hidden_activation_function))\n",
    "model2.add(Dropout(0.5))\n",
    "model2.add(Dense(classes, activation=final_activation_function))\n",
    "\n",
    "# Display the CNN.\n",
    "model2.summary()\n",
    "\n",
    "# Compile the model.\n",
    "model2.compile(loss=loss_method, optimizer=optimizer, metrics=[eval_metric])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4246 samples, validate on 750 samples\n",
      "Epoch 1/200\n",
      "4246/4246 [==============================] - 48s - loss: 1.6543 - acc: 0.2812 - val_loss: 4.9307 - val_acc: 0.0000e+00\n",
      "Epoch 2/200\n",
      "4246/4246 [==============================] - 47s - loss: 1.5931 - acc: 0.3069 - val_loss: 4.0383 - val_acc: 0.0000e+00\n",
      "Epoch 3/200\n",
      "4246/4246 [==============================] - 46s - loss: 1.5346 - acc: 0.3420 - val_loss: 4.1623 - val_acc: 0.0000e+00\n",
      "Epoch 4/200\n",
      "4246/4246 [==============================] - 46s - loss: 1.4778 - acc: 0.3846 - val_loss: 4.7397 - val_acc: 0.0000e+00\n",
      "Epoch 5/200\n",
      "4246/4246 [==============================] - 46s - loss: 1.4699 - acc: 0.3815 - val_loss: 5.1063 - val_acc: 0.0000e+00\n",
      "Epoch 6/200\n",
      "4246/4246 [==============================] - 46s - loss: 1.4468 - acc: 0.4103 - val_loss: 5.3261 - val_acc: 0.0000e+00\n",
      "Epoch 7/200\n",
      "4246/4246 [==============================] - 46s - loss: 1.4355 - acc: 0.4178 - val_loss: 4.9961 - val_acc: 0.0000e+00\n",
      "Epoch 8/200\n",
      "4246/4246 [==============================] - 46s - loss: 1.4327 - acc: 0.4025 - val_loss: 5.0772 - val_acc: 0.0000e+00\n",
      "Epoch 9/200\n",
      "4246/4246 [==============================] - 47s - loss: 1.4198 - acc: 0.4159 - val_loss: 5.5057 - val_acc: 0.0000e+00\n",
      "Epoch 10/200\n",
      "4246/4246 [==============================] - 46s - loss: 1.4146 - acc: 0.4216 - val_loss: 5.4646 - val_acc: 0.0000e+00\n",
      "Epoch 11/200\n",
      "4246/4246 [==============================] - 46s - loss: 1.3995 - acc: 0.4303 - val_loss: 5.6929 - val_acc: 0.0000e+00\n",
      "Epoch 12/200\n",
      "4246/4246 [==============================] - 46s - loss: 1.3927 - acc: 0.4322 - val_loss: 5.7267 - val_acc: 0.0000e+00\n",
      "Epoch 13/200\n",
      "4246/4246 [==============================] - 47s - loss: 1.3677 - acc: 0.4456 - val_loss: 5.7643 - val_acc: 0.0000e+00\n",
      "Epoch 14/200\n",
      "4246/4246 [==============================] - 46s - loss: 1.3564 - acc: 0.4447 - val_loss: 5.8028 - val_acc: 0.0000e+00\n",
      "Epoch 15/200\n",
      "4246/4246 [==============================] - 46s - loss: 1.3480 - acc: 0.4600 - val_loss: 6.2505 - val_acc: 0.0000e+00\n",
      "Epoch 16/200\n",
      "4246/4246 [==============================] - 46s - loss: 1.3323 - acc: 0.4520 - val_loss: 5.8724 - val_acc: 0.0000e+00\n",
      "Epoch 17/200\n",
      "4246/4246 [==============================] - 48s - loss: 1.3165 - acc: 0.4635 - val_loss: 6.4591 - val_acc: 0.0000e+00\n",
      "Epoch 18/200\n",
      "4246/4246 [==============================] - 46s - loss: 1.3063 - acc: 0.4597 - val_loss: 5.7935 - val_acc: 0.0000e+00\n",
      "Epoch 19/200\n",
      "4246/4246 [==============================] - 46s - loss: 1.2893 - acc: 0.4708 - val_loss: 6.2174 - val_acc: 0.0000e+00\n",
      "Epoch 20/200\n",
      "4246/4246 [==============================] - 46s - loss: 1.2633 - acc: 0.4863 - val_loss: 6.0547 - val_acc: 0.0000e+00\n",
      "Epoch 21/200\n",
      "4246/4246 [==============================] - 46s - loss: 1.2402 - acc: 0.4981 - val_loss: 6.0126 - val_acc: 0.0000e+00\n",
      "Epoch 22/200\n",
      "4246/4246 [==============================] - 47s - loss: 1.2331 - acc: 0.4925 - val_loss: 6.9671 - val_acc: 0.0000e+00\n",
      "Epoch 23/200\n",
      "4246/4246 [==============================] - 46s - loss: 1.1931 - acc: 0.5179 - val_loss: 6.8554 - val_acc: 0.0000e+00\n",
      "Epoch 24/200\n",
      "4246/4246 [==============================] - 46s - loss: 1.1637 - acc: 0.5386 - val_loss: 6.5733 - val_acc: 0.0000e+00\n",
      "Epoch 25/200\n",
      "4246/4246 [==============================] - 47s - loss: 1.1458 - acc: 0.5405 - val_loss: 6.8441 - val_acc: 0.0000e+00\n",
      "Epoch 26/200\n",
      "4246/4246 [==============================] - 46s - loss: 1.1119 - acc: 0.5608 - val_loss: 7.2572 - val_acc: 0.0000e+00\n",
      "Epoch 27/200\n",
      "4246/4246 [==============================] - 47s - loss: 1.1178 - acc: 0.5617 - val_loss: 6.6655 - val_acc: 0.0000e+00\n",
      "Epoch 28/200\n",
      "4246/4246 [==============================] - 46s - loss: 1.1141 - acc: 0.5561 - val_loss: 6.9619 - val_acc: 0.0000e+00\n",
      "Epoch 29/200\n",
      "4246/4246 [==============================] - 46s - loss: 1.0671 - acc: 0.5730 - val_loss: 7.5127 - val_acc: 0.0000e+00\n",
      "Epoch 30/200\n",
      "4246/4246 [==============================] - 46s - loss: 1.0853 - acc: 0.5742 - val_loss: 7.4175 - val_acc: 0.0000e+00\n",
      "Epoch 31/200\n",
      "4246/4246 [==============================] - 46s - loss: 1.0683 - acc: 0.5780 - val_loss: 7.2906 - val_acc: 0.0000e+00\n",
      "Epoch 32/200\n",
      "4246/4246 [==============================] - 46s - loss: 1.0089 - acc: 0.6090 - val_loss: 7.8413 - val_acc: 0.0000e+00\n",
      "Epoch 33/200\n",
      "4246/4246 [==============================] - 46s - loss: 1.0403 - acc: 0.5959 - val_loss: 6.8133 - val_acc: 0.0000e+00\n",
      "Epoch 34/200\n",
      "4246/4246 [==============================] - 46s - loss: 1.0594 - acc: 0.5869 - val_loss: 7.6736 - val_acc: 0.0000e+00\n",
      "Epoch 35/200\n",
      "4246/4246 [==============================] - 46s - loss: 0.9954 - acc: 0.6034 - val_loss: 7.7872 - val_acc: 0.0000e+00\n",
      "Epoch 36/200\n",
      "4246/4246 [==============================] - 46s - loss: 1.0262 - acc: 0.5926 - val_loss: 6.7215 - val_acc: 0.0000e+00\n",
      "Epoch 37/200\n",
      "4246/4246 [==============================] - 46s - loss: 1.0837 - acc: 0.5676 - val_loss: 7.3936 - val_acc: 0.0013\n",
      "Epoch 38/200\n",
      "4246/4246 [==============================] - 46s - loss: 0.9984 - acc: 0.6182 - val_loss: 8.0817 - val_acc: 0.0000e+00\n",
      "Epoch 39/200\n",
      "4246/4246 [==============================] - 46s - loss: 0.9283 - acc: 0.6465 - val_loss: 8.0904 - val_acc: 0.0013\n",
      "Epoch 40/200\n",
      "4246/4246 [==============================] - 46s - loss: 0.9106 - acc: 0.6510 - val_loss: 8.2826 - val_acc: 0.0000e+00\n",
      "Epoch 41/200\n",
      "4246/4246 [==============================] - 46s - loss: 0.9228 - acc: 0.6488 - val_loss: 7.7098 - val_acc: 0.0000e+00\n",
      "Epoch 42/200\n",
      "4246/4246 [==============================] - 46s - loss: 0.8933 - acc: 0.6455 - val_loss: 8.4293 - val_acc: 0.0000e+00\n",
      "Epoch 43/200\n",
      "4246/4246 [==============================] - 46s - loss: 0.8677 - acc: 0.6597 - val_loss: 8.4770 - val_acc: 0.0000e+00\n",
      "Epoch 44/200\n",
      "4246/4246 [==============================] - 61s - loss: 0.9040 - acc: 0.6474 - val_loss: 8.8484 - val_acc: 0.0013\n",
      "Epoch 45/200\n",
      "4246/4246 [==============================] - 61s - loss: 0.9498 - acc: 0.6390 - val_loss: 7.8537 - val_acc: 0.0013\n",
      "Epoch 46/200\n",
      "4246/4246 [==============================] - 62s - loss: 0.9281 - acc: 0.6361 - val_loss: 8.0037 - val_acc: 0.0013\n",
      "Epoch 47/200\n",
      "4246/4246 [==============================] - 61s - loss: 0.9205 - acc: 0.6425 - val_loss: 7.6085 - val_acc: 0.0000e+00\n",
      "Epoch 48/200\n",
      "4246/4246 [==============================] - 60s - loss: 0.8929 - acc: 0.6564 - val_loss: 8.6159 - val_acc: 0.0013\n",
      "Epoch 49/200\n",
      "4246/4246 [==============================] - 61s - loss: 0.8925 - acc: 0.6613 - val_loss: 8.3348 - val_acc: 0.0013\n",
      "Epoch 50/200\n",
      "4246/4246 [==============================] - 62s - loss: 0.8819 - acc: 0.6656 - val_loss: 8.6284 - val_acc: 0.0013\n",
      "Epoch 51/200\n",
      "4246/4246 [==============================] - 61s - loss: 0.8803 - acc: 0.6547 - val_loss: 8.2310 - val_acc: 0.0013\n",
      "Epoch 52/200\n",
      "4246/4246 [==============================] - 60s - loss: 0.8504 - acc: 0.6710 - val_loss: 8.3014 - val_acc: 0.0027\n",
      "Epoch 53/200\n",
      "4246/4246 [==============================] - 61s - loss: 0.8051 - acc: 0.6889 - val_loss: 8.5665 - val_acc: 0.0013\n",
      "Epoch 54/200\n",
      "4246/4246 [==============================] - 62s - loss: 0.7990 - acc: 0.6938 - val_loss: 9.8165 - val_acc: 0.0040\n",
      "Epoch 55/200\n",
      "4246/4246 [==============================] - 62s - loss: 0.7692 - acc: 0.7011 - val_loss: 8.9086 - val_acc: 0.0013\n",
      "Epoch 56/200\n",
      "4246/4246 [==============================] - 61s - loss: 0.8155 - acc: 0.6823 - val_loss: 9.1736 - val_acc: 0.0013\n",
      "Epoch 57/200\n",
      "4246/4246 [==============================] - 61s - loss: 0.7660 - acc: 0.7063 - val_loss: 9.2200 - val_acc: 0.0000e+00\n",
      "Epoch 58/200\n",
      "4246/4246 [==============================] - 62s - loss: 0.7779 - acc: 0.7004 - val_loss: 8.8094 - val_acc: 0.0027\n",
      "Epoch 59/200\n",
      "4246/4246 [==============================] - 62s - loss: 0.8316 - acc: 0.6766 - val_loss: 8.8835 - val_acc: 0.0040\n",
      "Epoch 60/200\n",
      "4246/4246 [==============================] - 61s - loss: 0.7973 - acc: 0.6978 - val_loss: 8.8544 - val_acc: 0.0013\n",
      "Epoch 61/200\n",
      "4246/4246 [==============================] - 61s - loss: 0.7349 - acc: 0.7228 - val_loss: 9.8787 - val_acc: 0.0013\n",
      "Epoch 62/200\n",
      "4246/4246 [==============================] - 62s - loss: 0.7714 - acc: 0.7084 - val_loss: 9.0893 - val_acc: 0.0040\n",
      "Epoch 63/200\n",
      "4246/4246 [==============================] - 62s - loss: 0.7780 - acc: 0.7016 - val_loss: 8.8863 - val_acc: 0.0027\n",
      "Epoch 64/200\n",
      "4246/4246 [==============================] - 61s - loss: 0.7666 - acc: 0.7077 - val_loss: 9.4003 - val_acc: 0.0027\n",
      "Epoch 65/200\n",
      "4246/4246 [==============================] - 60s - loss: 0.7426 - acc: 0.7209 - val_loss: 9.2093 - val_acc: 0.0027\n",
      "Epoch 66/200\n",
      "4246/4246 [==============================] - 62s - loss: 0.7629 - acc: 0.7221 - val_loss: 9.4273 - val_acc: 0.0040\n",
      "Epoch 67/200\n",
      "4246/4246 [==============================] - 62s - loss: 0.7597 - acc: 0.7117 - val_loss: 9.0988 - val_acc: 0.0027\n",
      "Epoch 68/200\n",
      "4246/4246 [==============================] - 61s - loss: 0.7721 - acc: 0.7049 - val_loss: 9.7775 - val_acc: 0.0027\n",
      "Epoch 69/200\n",
      "4246/4246 [==============================] - 61s - loss: 0.7453 - acc: 0.7256 - val_loss: 9.3751 - val_acc: 0.0000e+00\n",
      "Epoch 70/200\n",
      "4246/4246 [==============================] - 62s - loss: 0.7193 - acc: 0.7277 - val_loss: 9.5695 - val_acc: 0.0027\n",
      "Epoch 71/200\n",
      "4246/4246 [==============================] - 62s - loss: 0.7259 - acc: 0.7336 - val_loss: 8.7061 - val_acc: 0.0027\n",
      "Epoch 72/200\n",
      "4246/4246 [==============================] - 62s - loss: 0.7362 - acc: 0.7247 - val_loss: 9.4556 - val_acc: 0.0013\n",
      "Epoch 73/200\n",
      "4246/4246 [==============================] - 60s - loss: 0.7484 - acc: 0.7197 - val_loss: 9.3207 - val_acc: 0.0027\n",
      "Epoch 74/200\n",
      "4246/4246 [==============================] - 61s - loss: 0.7374 - acc: 0.7282 - val_loss: 8.7937 - val_acc: 0.0040\n",
      "Epoch 75/200\n",
      "4246/4246 [==============================] - 62s - loss: 0.6961 - acc: 0.7390 - val_loss: 9.9611 - val_acc: 0.0040\n",
      "Epoch 76/200\n",
      "4246/4246 [==============================] - 62s - loss: 0.7223 - acc: 0.7383 - val_loss: 8.9416 - val_acc: 0.0040\n",
      "Epoch 77/200\n",
      "4246/4246 [==============================] - 61s - loss: 0.6682 - acc: 0.7438 - val_loss: 10.0017 - val_acc: 0.0027\n",
      "Epoch 78/200\n",
      "4246/4246 [==============================] - 61s - loss: 0.7347 - acc: 0.7301 - val_loss: 9.3874 - val_acc: 0.0013\n",
      "Epoch 79/200\n",
      "4246/4246 [==============================] - 62s - loss: 0.7048 - acc: 0.7402 - val_loss: 9.3161 - val_acc: 0.0040\n",
      "Epoch 80/200\n",
      "4246/4246 [==============================] - 62s - loss: 0.7226 - acc: 0.7332 - val_loss: 9.5186 - val_acc: 0.0027\n",
      "Epoch 81/200\n",
      "4246/4246 [==============================] - 61s - loss: 0.7347 - acc: 0.7252 - val_loss: 8.8455 - val_acc: 0.0027\n",
      "Epoch 82/200\n",
      "4246/4246 [==============================] - 60s - loss: 0.6872 - acc: 0.7518 - val_loss: 9.7030 - val_acc: 0.0040\n",
      "Epoch 83/200\n",
      "4246/4246 [==============================] - 62s - loss: 0.6797 - acc: 0.7494 - val_loss: 9.8108 - val_acc: 0.0040\n",
      "Epoch 84/200\n",
      "4246/4246 [==============================] - 62s - loss: 0.7346 - acc: 0.7350 - val_loss: 9.5612 - val_acc: 0.0013\n",
      "Epoch 85/200\n",
      "4246/4246 [==============================] - 61s - loss: 0.6986 - acc: 0.7480 - val_loss: 10.1559 - val_acc: 0.0040\n",
      "Epoch 86/200\n",
      "4246/4246 [==============================] - 60s - loss: 0.7164 - acc: 0.7275 - val_loss: 10.8393 - val_acc: 0.0027\n",
      "Epoch 87/200\n",
      "4246/4246 [==============================] - 62s - loss: 0.8142 - acc: 0.7054 - val_loss: 8.9857 - val_acc: 0.0013\n",
      "Epoch 88/200\n",
      "4246/4246 [==============================] - 62s - loss: 0.7522 - acc: 0.7207 - val_loss: 9.4241 - val_acc: 0.0027\n",
      "Epoch 89/200\n",
      "4246/4246 [==============================] - 62s - loss: 0.6946 - acc: 0.7478 - val_loss: 9.9598 - val_acc: 0.0027\n",
      "Epoch 90/200\n",
      "4246/4246 [==============================] - 60s - loss: 0.7474 - acc: 0.7277 - val_loss: 9.1303 - val_acc: 0.0027\n",
      "Epoch 91/200\n",
      "4246/4246 [==============================] - 62s - loss: 0.6926 - acc: 0.7459 - val_loss: 10.0595 - val_acc: 0.0013\n",
      "Epoch 92/200\n",
      "4246/4246 [==============================] - 62s - loss: 0.6567 - acc: 0.7518 - val_loss: 10.1695 - val_acc: 0.0027\n",
      "Epoch 93/200\n",
      "4246/4246 [==============================] - 62s - loss: 0.7149 - acc: 0.7459 - val_loss: 9.5350 - val_acc: 0.0013\n",
      "Epoch 94/200\n",
      "4246/4246 [==============================] - 61s - loss: 0.7688 - acc: 0.7214 - val_loss: 10.1851 - val_acc: 0.0013\n",
      "Epoch 95/200\n",
      "4246/4246 [==============================] - 61s - loss: 0.7375 - acc: 0.7341 - val_loss: 9.2299 - val_acc: 0.0027\n",
      "Epoch 96/200\n",
      "4246/4246 [==============================] - 62s - loss: 0.6752 - acc: 0.7562 - val_loss: 9.9369 - val_acc: 0.0027\n",
      "Epoch 97/200\n",
      "4246/4246 [==============================] - 62s - loss: 0.7321 - acc: 0.7327 - val_loss: 9.1037 - val_acc: 0.0027\n",
      "Epoch 98/200\n",
      "4246/4246 [==============================] - 61s - loss: 0.7398 - acc: 0.7273 - val_loss: 9.4007 - val_acc: 0.0040\n",
      "Epoch 99/200\n",
      "4246/4246 [==============================] - 61s - loss: 0.7755 - acc: 0.7230 - val_loss: 9.3335 - val_acc: 0.0013\n",
      "Epoch 100/200\n",
      "4246/4246 [==============================] - 62s - loss: 0.7713 - acc: 0.7221 - val_loss: 9.6772 - val_acc: 0.0013\n",
      "Epoch 101/200\n",
      "4246/4246 [==============================] - 62s - loss: 0.7224 - acc: 0.7381 - val_loss: 9.5004 - val_acc: 0.0027\n",
      "Epoch 102/200\n",
      "4246/4246 [==============================] - 61s - loss: 0.7219 - acc: 0.7447 - val_loss: 10.4041 - val_acc: 0.0027\n",
      "Epoch 103/200\n",
      "4246/4246 [==============================] - 61s - loss: 0.7282 - acc: 0.7360 - val_loss: 10.6462 - val_acc: 0.0013\n",
      "Epoch 104/200\n",
      "4246/4246 [==============================] - 62s - loss: 0.6759 - acc: 0.7626 - val_loss: 9.7886 - val_acc: 0.0027\n",
      "Epoch 105/200\n",
      "4246/4246 [==============================] - 62s - loss: 0.6639 - acc: 0.7619 - val_loss: 9.3040 - val_acc: 0.0027\n",
      "Epoch 106/200\n",
      "4246/4246 [==============================] - 61s - loss: 0.6554 - acc: 0.7678 - val_loss: 9.7366 - val_acc: 0.0040\n",
      "Epoch 107/200\n",
      "4246/4246 [==============================] - 60s - loss: 0.6916 - acc: 0.7463 - val_loss: 10.3682 - val_acc: 0.0027\n",
      "Epoch 108/200\n",
      "4246/4246 [==============================] - 61s - loss: 0.7280 - acc: 0.7379 - val_loss: 8.9219 - val_acc: 0.0027\n",
      "Epoch 109/200\n",
      "4246/4246 [==============================] - 62s - loss: 0.7094 - acc: 0.7402 - val_loss: 9.3900 - val_acc: 0.0000e+00\n",
      "Epoch 110/200\n",
      "4246/4246 [==============================] - 61s - loss: 0.7648 - acc: 0.7301 - val_loss: 10.0271 - val_acc: 0.0013\n",
      "Epoch 111/200\n",
      "4246/4246 [==============================] - 60s - loss: 0.6900 - acc: 0.7478 - val_loss: 10.1493 - val_acc: 0.0027\n",
      "Epoch 112/200\n",
      "4246/4246 [==============================] - 61s - loss: 0.6908 - acc: 0.7475 - val_loss: 9.6455 - val_acc: 0.0040\n",
      "Epoch 113/200\n",
      "4246/4246 [==============================] - 62s - loss: 0.6595 - acc: 0.7607 - val_loss: 9.6973 - val_acc: 0.0040\n",
      "Epoch 114/200\n",
      "4246/4246 [==============================] - 62s - loss: 0.7292 - acc: 0.7456 - val_loss: 9.5485 - val_acc: 0.0027\n",
      "Epoch 115/200\n",
      "4246/4246 [==============================] - 61s - loss: 0.6611 - acc: 0.7624 - val_loss: 10.1871 - val_acc: 0.0027\n",
      "Epoch 116/200\n",
      "4246/4246 [==============================] - 61s - loss: 0.6886 - acc: 0.7537 - val_loss: 10.0778 - val_acc: 0.0027\n",
      "Epoch 117/200\n",
      "4246/4246 [==============================] - 62s - loss: 0.6975 - acc: 0.7471 - val_loss: 10.0438 - val_acc: 0.0027\n",
      "Epoch 118/200\n",
      "4246/4246 [==============================] - 62s - loss: 0.6617 - acc: 0.7584 - val_loss: 10.4678 - val_acc: 0.0027\n",
      "Epoch 119/200\n",
      "4246/4246 [==============================] - 61s - loss: 0.6338 - acc: 0.7711 - val_loss: 10.7867 - val_acc: 0.0013\n",
      "Epoch 120/200\n",
      "4246/4246 [==============================] - 61s - loss: 0.7465 - acc: 0.7332 - val_loss: 10.9384 - val_acc: 0.0040\n",
      "Epoch 121/200\n",
      "4246/4246 [==============================] - 62s - loss: 0.6804 - acc: 0.7565 - val_loss: 9.7673 - val_acc: 0.0040\n",
      "Epoch 122/200\n",
      "4246/4246 [==============================] - 62s - loss: 0.6941 - acc: 0.7555 - val_loss: 10.2308 - val_acc: 0.0027\n",
      "Epoch 123/200\n",
      "4246/4246 [==============================] - 61s - loss: 0.6714 - acc: 0.7657 - val_loss: 10.2469 - val_acc: 0.0040\n",
      "Epoch 124/200\n",
      "4246/4246 [==============================] - 61s - loss: 0.6912 - acc: 0.7520 - val_loss: 9.5807 - val_acc: 0.0040\n",
      "Epoch 125/200\n",
      "4246/4246 [==============================] - 62s - loss: 0.6917 - acc: 0.7492 - val_loss: 10.7000 - val_acc: 0.0040\n",
      "Epoch 126/200\n",
      "4246/4246 [==============================] - 62s - loss: 0.7092 - acc: 0.7463 - val_loss: 10.9108 - val_acc: 0.0013\n",
      "Epoch 127/200\n",
      "4246/4246 [==============================] - 61s - loss: 0.6630 - acc: 0.7704 - val_loss: 10.7820 - val_acc: 0.0013\n",
      "Epoch 128/200\n",
      "4246/4246 [==============================] - 60s - loss: 0.6729 - acc: 0.7612 - val_loss: 10.1051 - val_acc: 0.0027\n",
      "Epoch 129/200\n",
      "4246/4246 [==============================] - 61s - loss: 0.6483 - acc: 0.7678 - val_loss: 9.3876 - val_acc: 0.0027\n",
      "Epoch 130/200\n",
      "4246/4246 [==============================] - 62s - loss: 0.6644 - acc: 0.7647 - val_loss: 10.5910 - val_acc: 0.0027\n",
      "Epoch 131/200\n",
      "4246/4246 [==============================] - 62s - loss: 0.7317 - acc: 0.7475 - val_loss: 10.2135 - val_acc: 0.0040\n",
      "Epoch 132/200\n",
      "4246/4246 [==============================] - 60s - loss: 0.7630 - acc: 0.7376 - val_loss: 8.9396 - val_acc: 0.0040\n",
      "Epoch 133/200\n",
      "4246/4246 [==============================] - 61s - loss: 0.7591 - acc: 0.7341 - val_loss: 10.2474 - val_acc: 0.0040\n",
      "Epoch 134/200\n",
      "4246/4246 [==============================] - 62s - loss: 0.7472 - acc: 0.7412 - val_loss: 9.3397 - val_acc: 0.0040\n",
      "Epoch 135/200\n",
      "4246/4246 [==============================] - 62s - loss: 0.6937 - acc: 0.7435 - val_loss: 10.4522 - val_acc: 0.0027\n",
      "Epoch 136/200\n",
      "4246/4246 [==============================] - 61s - loss: 0.6194 - acc: 0.7869 - val_loss: 10.0054 - val_acc: 0.0027\n",
      "Epoch 137/200\n",
      "4246/4246 [==============================] - 61s - loss: 0.7778 - acc: 0.7339 - val_loss: 9.5037 - val_acc: 0.0040\n",
      "Epoch 138/200\n",
      "4246/4246 [==============================] - 62s - loss: 0.6811 - acc: 0.7673 - val_loss: 10.5293 - val_acc: 0.0027\n",
      "Epoch 139/200\n",
      "4246/4246 [==============================] - 62s - loss: 0.6514 - acc: 0.7680 - val_loss: 10.2180 - val_acc: 0.0040\n",
      "Epoch 140/200\n",
      "4246/4246 [==============================] - 61s - loss: 0.6792 - acc: 0.7631 - val_loss: 10.1332 - val_acc: 0.0040\n",
      "Epoch 141/200\n",
      "4246/4246 [==============================] - 60s - loss: 0.7089 - acc: 0.7541 - val_loss: 10.2003 - val_acc: 0.0013\n",
      "Epoch 142/200\n",
      "4246/4246 [==============================] - 61s - loss: 0.7167 - acc: 0.7534 - val_loss: 9.7133 - val_acc: 0.0013\n",
      "Epoch 143/200\n",
      "4246/4246 [==============================] - 61s - loss: 0.7104 - acc: 0.7499 - val_loss: 10.0663 - val_acc: 0.0013\n",
      "Epoch 144/200\n",
      "4246/4246 [==============================] - 62s - loss: 0.6703 - acc: 0.7633 - val_loss: 10.2451 - val_acc: 0.0013\n",
      "Epoch 145/200\n",
      "4246/4246 [==============================] - 60s - loss: 0.7003 - acc: 0.7506 - val_loss: 9.8081 - val_acc: 0.0040\n",
      "Epoch 146/200\n",
      "4246/4246 [==============================] - 61s - loss: 0.6585 - acc: 0.7605 - val_loss: 10.8591 - val_acc: 0.0027\n",
      "Epoch 147/200\n",
      "4246/4246 [==============================] - 61s - loss: 0.7162 - acc: 0.7541 - val_loss: 9.7047 - val_acc: 0.0040\n",
      "Epoch 148/200\n",
      "4246/4246 [==============================] - 62s - loss: 0.7540 - acc: 0.7468 - val_loss: 9.8108 - val_acc: 0.0027\n",
      "Epoch 149/200\n",
      "4246/4246 [==============================] - 60s - loss: 0.7285 - acc: 0.7489 - val_loss: 9.9970 - val_acc: 0.0040\n",
      "Epoch 150/200\n",
      "4246/4246 [==============================] - 61s - loss: 0.6417 - acc: 0.7767 - val_loss: 10.7716 - val_acc: 0.0040\n",
      "Epoch 151/200\n",
      "4246/4246 [==============================] - 62s - loss: 0.7127 - acc: 0.7489 - val_loss: 10.9927 - val_acc: 0.0040\n",
      "Epoch 152/200\n",
      "4246/4246 [==============================] - 62s - loss: 0.6938 - acc: 0.7562 - val_loss: 10.5830 - val_acc: 0.0027\n",
      "Epoch 153/200\n",
      "4246/4246 [==============================] - 61s - loss: 0.6829 - acc: 0.7687 - val_loss: 10.0827 - val_acc: 0.0040\n",
      "Epoch 154/200\n",
      "4246/4246 [==============================] - 61s - loss: 0.6117 - acc: 0.7833 - val_loss: 10.4504 - val_acc: 0.0027\n",
      "Epoch 155/200\n",
      "4246/4246 [==============================] - 61s - loss: 0.6565 - acc: 0.7711 - val_loss: 10.8042 - val_acc: 0.0013\n",
      "Epoch 156/200\n",
      "4246/4246 [==============================] - 62s - loss: 0.6449 - acc: 0.7699 - val_loss: 10.3649 - val_acc: 0.0027\n",
      "Epoch 157/200\n",
      "4246/4246 [==============================] - 61s - loss: 0.6737 - acc: 0.7793 - val_loss: 9.4061 - val_acc: 0.0027\n",
      "Epoch 158/200\n",
      "4246/4246 [==============================] - 61s - loss: 0.6667 - acc: 0.7737 - val_loss: 9.7507 - val_acc: 0.0027\n",
      "Epoch 159/200\n",
      "4246/4246 [==============================] - 61s - loss: 0.6324 - acc: 0.7918 - val_loss: 10.0627 - val_acc: 0.0040\n",
      "Epoch 160/200\n",
      "4246/4246 [==============================] - 62s - loss: 0.6199 - acc: 0.7831 - val_loss: 10.7593 - val_acc: 0.0027\n",
      "Epoch 161/200\n",
      "4246/4246 [==============================] - 61s - loss: 0.6589 - acc: 0.7748 - val_loss: 10.0019 - val_acc: 0.0040\n",
      "Epoch 162/200\n",
      "4246/4246 [==============================] - 60s - loss: 0.7211 - acc: 0.7572 - val_loss: 9.4587 - val_acc: 0.0013\n",
      "Epoch 163/200\n",
      "4246/4246 [==============================] - 61s - loss: 0.6384 - acc: 0.7751 - val_loss: 10.1550 - val_acc: 0.0027\n",
      "Epoch 164/200\n",
      "4246/4246 [==============================] - 62s - loss: 0.6663 - acc: 0.7753 - val_loss: 10.5507 - val_acc: 0.0013\n",
      "Epoch 165/200\n",
      "4246/4246 [==============================] - 62s - loss: 0.6059 - acc: 0.7873 - val_loss: 10.8503 - val_acc: 0.0013\n",
      "Epoch 166/200\n",
      "4246/4246 [==============================] - 61s - loss: 0.6581 - acc: 0.7819 - val_loss: 10.5434 - val_acc: 0.0013\n",
      "Epoch 167/200\n",
      "4246/4246 [==============================] - 60s - loss: 0.6600 - acc: 0.7744 - val_loss: 9.9095 - val_acc: 0.0027\n",
      "Epoch 168/200\n",
      "4246/4246 [==============================] - 62s - loss: 0.6169 - acc: 0.7850 - val_loss: 10.0534 - val_acc: 0.0027\n",
      "Epoch 169/200\n",
      "4246/4246 [==============================] - 62s - loss: 0.7527 - acc: 0.7475 - val_loss: 10.8539 - val_acc: 0.0013\n",
      "Epoch 170/200\n",
      "4246/4246 [==============================] - 62s - loss: 0.7137 - acc: 0.7572 - val_loss: 10.4685 - val_acc: 0.0027\n",
      "Epoch 171/200\n",
      "4246/4246 [==============================] - 61s - loss: 0.6896 - acc: 0.7694 - val_loss: 10.2484 - val_acc: 0.0027\n",
      "Epoch 172/200\n",
      "4246/4246 [==============================] - 62s - loss: 0.7105 - acc: 0.7588 - val_loss: 11.1754 - val_acc: 0.0027\n",
      "Epoch 173/200\n",
      "4246/4246 [==============================] - 62s - loss: 0.6613 - acc: 0.7760 - val_loss: 10.4675 - val_acc: 0.0027\n",
      "Epoch 174/200\n",
      "4246/4246 [==============================] - 62s - loss: 0.6023 - acc: 0.7960 - val_loss: 10.6687 - val_acc: 0.0027\n",
      "Epoch 175/200\n",
      "4246/4246 [==============================] - 60s - loss: 0.7979 - acc: 0.7221 - val_loss: 9.9524 - val_acc: 0.0027\n",
      "Epoch 176/200\n",
      "4246/4246 [==============================] - 62s - loss: 0.7394 - acc: 0.7456 - val_loss: 10.3615 - val_acc: 0.0027\n",
      "Epoch 177/200\n",
      "4246/4246 [==============================] - 62s - loss: 0.6056 - acc: 0.7930 - val_loss: 10.3804 - val_acc: 0.0040\n",
      "Epoch 178/200\n",
      "4246/4246 [==============================] - 62s - loss: 0.6526 - acc: 0.7852 - val_loss: 11.2362 - val_acc: 0.0027\n",
      "Epoch 179/200\n",
      "4246/4246 [==============================] - 60s - loss: 0.7016 - acc: 0.7607 - val_loss: 10.8682 - val_acc: 0.0040\n",
      "Epoch 180/200\n",
      "4246/4246 [==============================] - 61s - loss: 0.6293 - acc: 0.7902 - val_loss: 10.2922 - val_acc: 0.0040\n",
      "Epoch 181/200\n",
      "4246/4246 [==============================] - 62s - loss: 0.6551 - acc: 0.7730 - val_loss: 9.8685 - val_acc: 0.0027\n",
      "Epoch 182/200\n",
      "4246/4246 [==============================] - 62s - loss: 0.7135 - acc: 0.7541 - val_loss: 11.0323 - val_acc: 0.0013\n",
      "Epoch 183/200\n",
      "4246/4246 [==============================] - 60s - loss: 0.6683 - acc: 0.7715 - val_loss: 10.3755 - val_acc: 0.0013\n",
      "Epoch 184/200\n",
      "4246/4246 [==============================] - 61s - loss: 0.6837 - acc: 0.7584 - val_loss: 10.6354 - val_acc: 0.0013\n",
      "Epoch 185/200\n",
      "4246/4246 [==============================] - 62s - loss: 0.6442 - acc: 0.7781 - val_loss: 10.9696 - val_acc: 0.0013\n",
      "Epoch 186/200\n",
      "4246/4246 [==============================] - 62s - loss: 0.6572 - acc: 0.7800 - val_loss: 9.6747 - val_acc: 0.0027\n",
      "Epoch 187/200\n",
      "4246/4246 [==============================] - 61s - loss: 0.6490 - acc: 0.7774 - val_loss: 10.2108 - val_acc: 0.0013\n",
      "Epoch 188/200\n",
      "4246/4246 [==============================] - 60s - loss: 0.6486 - acc: 0.7760 - val_loss: 10.6893 - val_acc: 0.0013\n",
      "Epoch 189/200\n",
      "4246/4246 [==============================] - 62s - loss: 0.6646 - acc: 0.7779 - val_loss: 10.3284 - val_acc: 0.0027\n",
      "Epoch 190/200\n",
      "4246/4246 [==============================] - 62s - loss: 0.6628 - acc: 0.7774 - val_loss: 10.1757 - val_acc: 0.0013\n",
      "Epoch 191/200\n",
      "4246/4246 [==============================] - 61s - loss: 0.7455 - acc: 0.7489 - val_loss: 10.2112 - val_acc: 0.0013\n",
      "Epoch 192/200\n",
      "4246/4246 [==============================] - 61s - loss: 0.6507 - acc: 0.7741 - val_loss: 10.9271 - val_acc: 0.0013\n",
      "Epoch 193/200\n",
      "4246/4246 [==============================] - 62s - loss: 0.6478 - acc: 0.7803 - val_loss: 9.9182 - val_acc: 0.0000e+00\n",
      "Epoch 194/200\n",
      "4246/4246 [==============================] - 62s - loss: 0.6580 - acc: 0.7765 - val_loss: 10.5871 - val_acc: 0.0027\n",
      "Epoch 195/200\n",
      "4246/4246 [==============================] - 62s - loss: 0.6759 - acc: 0.7838 - val_loss: 11.4325 - val_acc: 0.0013\n",
      "Epoch 196/200\n",
      "4246/4246 [==============================] - 61s - loss: 0.6531 - acc: 0.7862 - val_loss: 10.5200 - val_acc: 0.0027\n",
      "Epoch 197/200\n",
      "4246/4246 [==============================] - 61s - loss: 0.7272 - acc: 0.7586 - val_loss: 10.3617 - val_acc: 0.0027\n",
      "Epoch 198/200\n",
      "4246/4246 [==============================] - 61s - loss: 0.7795 - acc: 0.7327 - val_loss: 9.5595 - val_acc: 0.0027\n",
      "Epoch 199/200\n",
      "4246/4246 [==============================] - 62s - loss: 0.7362 - acc: 0.7518 - val_loss: 10.3716 - val_acc: 0.0013\n",
      "Epoch 200/200\n",
      "4246/4246 [==============================] - 60s - loss: 0.7326 - acc: 0.7402 - val_loss: 10.6330 - val_acc: 0.0000e+00\n",
      "Test loss: 2.31069281969\n",
      "Test accuracy: 0.599799398195\n"
     ]
    }
   ],
   "source": [
    "# The actual training of the CNN using the parameters and model previously specified.\n",
    "# The validation set is a split of the stratified sampled training data.\n",
    "history2 = model2.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_split = 0.15)\n",
    "\n",
    "# Evaluate the performance on the unused testing set.\n",
    "score2 = model2.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score2[0])\n",
    "print('Test accuracy:', score2[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model2.save_weights('tuned_weights2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<keras.layers.convolutional.Conv2D at 0x130cc9a90>,\n",
       " <keras.layers.pooling.MaxPooling2D at 0x130702e10>,\n",
       " <keras.layers.convolutional.Conv2D at 0x130702c50>,\n",
       " <keras.layers.core.Dropout at 0x130702210>,\n",
       " <keras.layers.pooling.MaxPooling2D at 0x130cc9ed0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x129737b50>,\n",
       " <keras.layers.core.Dropout at 0x13071d990>,\n",
       " <keras.layers.pooling.MaxPooling2D at 0x129ac4fd0>,\n",
       " <keras.layers.core.Flatten at 0x115c0e710>,\n",
       " <keras.layers.core.Dense at 0x115c1bbd0>,\n",
       " <keras.layers.core.Dropout at 0x129aadd90>,\n",
       " <keras.layers.core.Dense at 0x115c61890>]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfcAAAFtCAYAAAAaiCMCAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIXCKAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11974bd10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# here is a visualization of the training process\n",
    "# typically we gain a lot in the beginning and then\n",
    "# training slows down\n",
    "plt.plot(history2.history['acc'])\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.title(\"Training Accuracy, Additional Layers\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above results, we see that this model with 250 epochs and nother convultional, dropout, and pooling layer  yielded an accuracy of ~60% on the unseen test set, and 75% accuracy on the training set.  This is a reduction of 20% accuracy on the training set and a 10% reduction on the test set, from the previous, simpler model.  It is believed that the addition of the convolutional layer and pooling layer are simplifing the details of the image excessively and loosing detail."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Tune an existing CNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.preprocessing import image\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, GlobalAveragePooling2D\n",
    "from keras import backend as K\n",
    "\n",
    "# create the base pre-trained model\n",
    "base_model = InceptionV3(weights='imagenet', include_top=False)\n",
    "\n",
    "# add a global spatial average pooling layer\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "# let's add a fully-connected layer\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "# and a logistic layer \n",
    "predictions = Dense(classes, activation=final_activation_function)(x)\n",
    "\n",
    "# this is the model we will train\n",
    "model_tune = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# first: train only the top layers (which were randomly initialized)\n",
    "# i.e. freeze all convolutional InceptionV3 layers\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# compile the model (should be done *after* setting layers to non-trainable)\n",
    "model_tune.compile(optimizer='rmsprop', loss='categorical_crossentropy',  metrics=[eval_metric])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<keras.engine.topology.InputLayer at 0x117c330d0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x119c6e590>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x1307c2550>,\n",
       " <keras.layers.core.Activation at 0x117c33f50>,\n",
       " <keras.layers.convolutional.Conv2D at 0x159cebe90>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x117c33e90>,\n",
       " <keras.layers.core.Activation at 0x135185790>,\n",
       " <keras.layers.convolutional.Conv2D at 0x130852b50>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x12556a210>,\n",
       " <keras.layers.core.Activation at 0x12555bdd0>,\n",
       " <keras.layers.pooling.MaxPooling2D at 0x130bbd250>,\n",
       " <keras.layers.convolutional.Conv2D at 0x1308e9bd0>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x130bdb8d0>,\n",
       " <keras.layers.core.Activation at 0x134088d90>,\n",
       " <keras.layers.convolutional.Conv2D at 0x13535ddd0>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x13536eb90>,\n",
       " <keras.layers.core.Activation at 0x146bcc250>,\n",
       " <keras.layers.pooling.MaxPooling2D at 0x134097c50>,\n",
       " <keras.layers.convolutional.Conv2D at 0x156180450>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x1560a0ed0>,\n",
       " <keras.layers.core.Activation at 0x15635ee10>,\n",
       " <keras.layers.convolutional.Conv2D at 0x15541e650>,\n",
       " <keras.layers.convolutional.Conv2D at 0x1563883d0>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x1555601d0>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x15636c590>,\n",
       " <keras.layers.core.Activation at 0x155c3da90>,\n",
       " <keras.layers.core.Activation at 0x1565f28d0>,\n",
       " <keras.layers.pooling.AveragePooling2D at 0x156cddcd0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x146b71910>,\n",
       " <keras.layers.convolutional.Conv2D at 0x155f9f850>,\n",
       " <keras.layers.convolutional.Conv2D at 0x1565d2fd0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x15661c450>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x146bec8d0>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x15542e450>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x156549790>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x156d1de10>,\n",
       " <keras.layers.core.Activation at 0x15541eed0>,\n",
       " <keras.layers.core.Activation at 0x1561c3dd0>,\n",
       " <keras.layers.core.Activation at 0x156cc2610>,\n",
       " <keras.layers.core.Activation at 0x156fa0950>,\n",
       " <keras.layers.merge.Concatenate at 0x156fbc250>,\n",
       " <keras.layers.convolutional.Conv2D at 0x157aa0f50>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x157ae5790>,\n",
       " <keras.layers.core.Activation at 0x157ec64d0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x1574f9ad0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x157a38f10>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x1575077d0>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x157e92a90>,\n",
       " <keras.layers.core.Activation at 0x1577c9c50>,\n",
       " <keras.layers.core.Activation at 0x158456290>,\n",
       " <keras.layers.pooling.AveragePooling2D at 0x15856ead0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x156fe9910>,\n",
       " <keras.layers.convolutional.Conv2D at 0x157980e90>,\n",
       " <keras.layers.convolutional.Conv2D at 0x157f12e90>,\n",
       " <keras.layers.convolutional.Conv2D at 0x15857c7d0>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x1574ac8d0>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x1577c9f10>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x157f32e10>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x157fe41d0>,\n",
       " <keras.layers.core.Activation at 0x15758b5d0>,\n",
       " <keras.layers.core.Activation at 0x157a57550>,\n",
       " <keras.layers.core.Activation at 0x158513e90>,\n",
       " <keras.layers.core.Activation at 0x15889a1d0>,\n",
       " <keras.layers.merge.Concatenate at 0x1588efd90>,\n",
       " <keras.layers.convolutional.Conv2D at 0x158c39d50>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x158d6ca50>,\n",
       " <keras.layers.core.Activation at 0x158e7ea90>,\n",
       " <keras.layers.convolutional.Conv2D at 0x158b31f90>,\n",
       " <keras.layers.convolutional.Conv2D at 0x158e65f90>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x15882b110>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x158e57790>,\n",
       " <keras.layers.core.Activation at 0x158b8a550>,\n",
       " <keras.layers.core.Activation at 0x158f847d0>,\n",
       " <keras.layers.pooling.AveragePooling2D at 0x159100f10>,\n",
       " <keras.layers.convolutional.Conv2D at 0x158800e90>,\n",
       " <keras.layers.convolutional.Conv2D at 0x158ce1450>,\n",
       " <keras.layers.convolutional.Conv2D at 0x158f5eed0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x159044d90>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x1588e0410>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x158cb0c50>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x158f6acd0>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x159055290>,\n",
       " <keras.layers.core.Activation at 0x158babdd0>,\n",
       " <keras.layers.core.Activation at 0x158d75b50>,\n",
       " <keras.layers.core.Activation at 0x1590636d0>,\n",
       " <keras.layers.core.Activation at 0x159195990>,\n",
       " <keras.layers.merge.Concatenate at 0x15916af90>,\n",
       " <keras.layers.convolutional.Conv2D at 0x1592d10d0>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x159274b50>,\n",
       " <keras.layers.core.Activation at 0x159617cd0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x159378fd0>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x159387950>,\n",
       " <keras.layers.core.Activation at 0x159b42e50>,\n",
       " <keras.layers.convolutional.Conv2D at 0x159186590>,\n",
       " <keras.layers.convolutional.Conv2D at 0x159b6b410>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x159226b10>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x159b50650>,\n",
       " <keras.layers.core.Activation at 0x159284c10>,\n",
       " <keras.layers.core.Activation at 0x159c48650>,\n",
       " <keras.layers.pooling.MaxPooling2D at 0x1596733d0>,\n",
       " <keras.layers.merge.Concatenate at 0x159bfa7d0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x15cb3c110>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x15cb59510>,\n",
       " <keras.layers.core.Activation at 0x15f1dc590>,\n",
       " <keras.layers.convolutional.Conv2D at 0x161d37cd0>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x161d777d0>,\n",
       " <keras.layers.core.Activation at 0x162f5f4d0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x15b265dd0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x15f1bbf50>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x159e83d10>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x162f8bd90>,\n",
       " <keras.layers.core.Activation at 0x15b256450>,\n",
       " <keras.layers.core.Activation at 0x163074910>,\n",
       " <keras.layers.convolutional.Conv2D at 0x15b7af250>,\n",
       " <keras.layers.convolutional.Conv2D at 0x16303ad10>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x15b515910>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x16302af90>,\n",
       " <keras.layers.core.Activation at 0x15c5bf610>,\n",
       " <keras.layers.core.Activation at 0x163140f10>,\n",
       " <keras.layers.pooling.AveragePooling2D at 0x1638be990>,\n",
       " <keras.layers.convolutional.Conv2D at 0x159bfab50>,\n",
       " <keras.layers.convolutional.Conv2D at 0x15c596e50>,\n",
       " <keras.layers.convolutional.Conv2D at 0x163198b10>,\n",
       " <keras.layers.convolutional.Conv2D at 0x1638a6750>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x159dd4890>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x15c5a6890>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x163120410>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x163897f90>,\n",
       " <keras.layers.core.Activation at 0x159eb0cd0>,\n",
       " <keras.layers.core.Activation at 0x15cb82910>,\n",
       " <keras.layers.core.Activation at 0x1638d13d0>,\n",
       " <keras.layers.core.Activation at 0x163960c10>,\n",
       " <keras.layers.merge.Concatenate at 0x1639f8250>,\n",
       " <keras.layers.convolutional.Conv2D at 0x163dbcf50>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x163dcb710>,\n",
       " <keras.layers.core.Activation at 0x163ec3a10>,\n",
       " <keras.layers.convolutional.Conv2D at 0x163eb3310>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x163ea3c10>,\n",
       " <keras.layers.core.Activation at 0x163f7b610>,\n",
       " <keras.layers.convolutional.Conv2D at 0x163b424d0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x163eec250>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x163b0cf90>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x163fa9bd0>,\n",
       " <keras.layers.core.Activation at 0x163c57290>,\n",
       " <keras.layers.core.Activation at 0x164092650>,\n",
       " <keras.layers.convolutional.Conv2D at 0x163b8ee90>,\n",
       " <keras.layers.convolutional.Conv2D at 0x16415a410>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x163babe10>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x164129ad0>,\n",
       " <keras.layers.core.Activation at 0x163cc3e90>,\n",
       " <keras.layers.core.Activation at 0x1641effd0>,\n",
       " <keras.layers.pooling.AveragePooling2D at 0x16436c850>,\n",
       " <keras.layers.convolutional.Conv2D at 0x1639d8750>,\n",
       " <keras.layers.convolutional.Conv2D at 0x163d20ad0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x1640afd10>,\n",
       " <keras.layers.convolutional.Conv2D at 0x1642e1f50>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x16399f910>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x163d2f7d0>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x1641e7a10>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x16432c810>,\n",
       " <keras.layers.core.Activation at 0x163aa7e50>,\n",
       " <keras.layers.core.Activation at 0x163df5390>,\n",
       " <keras.layers.core.Activation at 0x1642ee710>,\n",
       " <keras.layers.core.Activation at 0x16438bad0>,\n",
       " <keras.layers.merge.Concatenate at 0x164480290>,\n",
       " <keras.layers.convolutional.Conv2D at 0x164959450>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x164920ed0>,\n",
       " <keras.layers.core.Activation at 0x164a19e10>,\n",
       " <keras.layers.convolutional.Conv2D at 0x164a413d0>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x164a29590>,\n",
       " <keras.layers.core.Activation at 0x164b228d0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x164544e10>,\n",
       " <keras.layers.convolutional.Conv2D at 0x164b02fd0>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x1644caed0>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x164ad4790>,\n",
       " <keras.layers.core.Activation at 0x1645b15d0>,\n",
       " <keras.layers.core.Activation at 0x164c27610>,\n",
       " <keras.layers.convolutional.Conv2D at 0x1645568d0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x164c41cd0>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x16474f1d0>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x164b4c550>,\n",
       " <keras.layers.core.Activation at 0x16481ca90>,\n",
       " <keras.layers.core.Activation at 0x164d87d90>,\n",
       " <keras.layers.pooling.AveragePooling2D at 0x164e8eb90>,\n",
       " <keras.layers.convolutional.Conv2D at 0x1644208d0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x164895850>,\n",
       " <keras.layers.convolutional.Conv2D at 0x164c08ed0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x164e24f10>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x1643d7e10>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x1645d4c90>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x164d98bd0>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x164ec0e90>,\n",
       " <keras.layers.core.Activation at 0x16440fa50>,\n",
       " <keras.layers.core.Activation at 0x16499add0>,\n",
       " <keras.layers.core.Activation at 0x164e35f50>,\n",
       " <keras.layers.core.Activation at 0x164f0ee90>,\n",
       " <keras.layers.merge.Concatenate at 0x164f0e610>,\n",
       " <keras.layers.convolutional.Conv2D at 0x1653b3ad0>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x1653c47d0>,\n",
       " <keras.layers.core.Activation at 0x165cbc390>,\n",
       " <keras.layers.convolutional.Conv2D at 0x165c83f50>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x165c92710>,\n",
       " <keras.layers.core.Activation at 0x165d89a10>,\n",
       " <keras.layers.convolutional.Conv2D at 0x165090f50>,\n",
       " <keras.layers.convolutional.Conv2D at 0x165d78310>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x1650d2790>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x165d6bc10>,\n",
       " <keras.layers.core.Activation at 0x1651d94d0>,\n",
       " <keras.layers.core.Activation at 0x165e45610>,\n",
       " <keras.layers.convolutional.Conv2D at 0x165024690>,\n",
       " <keras.layers.convolutional.Conv2D at 0x165db2250>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x1651a5a90>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x165e71bd0>,\n",
       " <keras.layers.core.Activation at 0x1652ef290>,\n",
       " <keras.layers.core.Activation at 0x165f5e650>,\n",
       " <keras.layers.pooling.AveragePooling2D at 0x165f7cd10>,\n",
       " <keras.layers.convolutional.Conv2D at 0x16397f9d0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x165224e90>,\n",
       " <keras.layers.convolutional.Conv2D at 0x166024410>,\n",
       " <keras.layers.convolutional.Conv2D at 0x1660ada10>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x164f74c10>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x165243e10>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x165ff2ad0>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x1660f98d0>,\n",
       " <keras.layers.core.Activation at 0x165045810>,\n",
       " <keras.layers.core.Activation at 0x165359e90>,\n",
       " <keras.layers.core.Activation at 0x1660b8fd0>,\n",
       " <keras.layers.core.Activation at 0x1661a6550>,\n",
       " <keras.layers.merge.Concatenate at 0x1662344d0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x1662d8610>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x166394b50>,\n",
       " <keras.layers.core.Activation at 0x16647f5d0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x16641e8d0>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x1664f61d0>,\n",
       " <keras.layers.core.Activation at 0x1665c5a90>,\n",
       " <keras.layers.convolutional.Conv2D at 0x16615d110>,\n",
       " <keras.layers.convolutional.Conv2D at 0x16663d850>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x166223c50>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x16649dc90>,\n",
       " <keras.layers.core.Activation at 0x1662ad990>,\n",
       " <keras.layers.core.Activation at 0x166746dd0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x1662ca290>,\n",
       " <keras.layers.convolutional.Conv2D at 0x166702450>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x1662f7950>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x1666c9ed0>,\n",
       " <keras.layers.core.Activation at 0x166368590>,\n",
       " <keras.layers.core.Activation at 0x1667c0e10>,\n",
       " <keras.layers.pooling.MaxPooling2D at 0x1667e93d0>,\n",
       " <keras.layers.merge.Concatenate at 0x166722f90>,\n",
       " <keras.layers.convolutional.Conv2D at 0x166c2c790>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x166c5edd0>,\n",
       " <keras.layers.core.Activation at 0x166c89dd0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x1668bac10>,\n",
       " <keras.layers.convolutional.Conv2D at 0x166d40450>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x1668a99d0>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x166d0ef10>,\n",
       " <keras.layers.core.Activation at 0x1669b1610>,\n",
       " <keras.layers.core.Activation at 0x166daca50>,\n",
       " <keras.layers.convolutional.Conv2D at 0x1669cacd0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x166993ed0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x166dd4b50>,\n",
       " <keras.layers.convolutional.Conv2D at 0x166ec1f90>,\n",
       " <keras.layers.pooling.AveragePooling2D at 0x167047e90>,\n",
       " <keras.layers.convolutional.Conv2D at 0x1667d05d0>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x16693fb10>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x166b10bd0>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x166dc9a50>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x166eb4790>,\n",
       " <keras.layers.convolutional.Conv2D at 0x167077850>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x16684eb10>,\n",
       " <keras.layers.core.Activation at 0x166afdd90>,\n",
       " <keras.layers.core.Activation at 0x166baef50>,\n",
       " <keras.layers.core.Activation at 0x166edca90>,\n",
       " <keras.layers.core.Activation at 0x166fe27d0>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x166fc9cd0>,\n",
       " <keras.layers.core.Activation at 0x16694cfd0>,\n",
       " <keras.layers.merge.Concatenate at 0x166c0bb90>,\n",
       " <keras.layers.merge.Concatenate at 0x166fb9ed0>,\n",
       " <keras.layers.core.Activation at 0x1670a2f50>,\n",
       " <keras.layers.merge.Concatenate at 0x1670a2fd0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x1673c6710>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x1675aa2d0>,\n",
       " <keras.layers.core.Activation at 0x16764edd0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x1671dae10>,\n",
       " <keras.layers.convolutional.Conv2D at 0x1675d4f90>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x1671e8c10>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x1674d0550>,\n",
       " <keras.layers.core.Activation at 0x1672e0610>,\n",
       " <keras.layers.core.Activation at 0x16762e550>,\n",
       " <keras.layers.convolutional.Conv2D at 0x1672c0fd0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x1673ffcd0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x167787450>,\n",
       " <keras.layers.convolutional.Conv2D at 0x1676dbd50>,\n",
       " <keras.layers.pooling.AveragePooling2D at 0x16790b9d0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x1670eb950>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x167295b10>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x16730a550>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x167754c50>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x167814a50>,\n",
       " <keras.layers.convolutional.Conv2D at 0x1679e34d0>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x16718ab90>,\n",
       " <keras.layers.core.Activation at 0x1673e5610>,\n",
       " <keras.layers.core.Activation at 0x167547d90>,\n",
       " <keras.layers.core.Activation at 0x16781fb50>,\n",
       " <keras.layers.core.Activation at 0x167924a90>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x1679b8d10>,\n",
       " <keras.layers.core.Activation at 0x167236c10>,\n",
       " <keras.layers.merge.Concatenate at 0x1673c6ed0>,\n",
       " <keras.layers.merge.Concatenate at 0x16790bf90>,\n",
       " <keras.layers.core.Activation at 0x1679f5310>,\n",
       " <keras.layers.merge.Concatenate at 0x1679f5550>,\n",
       " <keras.layers.pooling.GlobalAveragePooling2D at 0x117c339d0>,\n",
       " <keras.layers.core.Dense at 0x117c33a10>,\n",
       " <keras.layers.core.Dense at 0x167a5c9d0>]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_tune.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4246 samples, validate on 750 samples\n",
      "Epoch 1/10\n",
      "4246/4246 [==============================] - 238s - loss: 2.5429 - acc: 0.2946 - val_loss: 15.6984 - val_acc: 0.0000e+00\n",
      "Epoch 2/10\n",
      "4246/4246 [==============================] - 222s - loss: 1.6082 - acc: 0.4030 - val_loss: 15.0893 - val_acc: 0.0000e+00\n",
      "Epoch 3/10\n",
      "4246/4246 [==============================] - 219s - loss: 1.4652 - acc: 0.4402 - val_loss: 14.8802 - val_acc: 0.0000e+00\n",
      "Epoch 4/10\n",
      "4246/4246 [==============================] - 223s - loss: 1.3619 - acc: 0.4965 - val_loss: 14.6007 - val_acc: 0.0000e+00\n",
      "Epoch 5/10\n",
      "4246/4246 [==============================] - 219s - loss: 1.3112 - acc: 0.4981 - val_loss: 14.2790 - val_acc: 0.0000e+00\n",
      "Epoch 6/10\n",
      "4246/4246 [==============================] - 239s - loss: 1.1826 - acc: 0.5681 - val_loss: 14.1250 - val_acc: 0.0000e+00\n",
      "Epoch 7/10\n",
      "4246/4246 [==============================] - 282s - loss: 1.1283 - acc: 0.5805 - val_loss: 13.4975 - val_acc: 0.0000e+00\n",
      "Epoch 8/10\n",
      "4246/4246 [==============================] - 235s - loss: 1.0661 - acc: 0.6126 - val_loss: 13.6617 - val_acc: 0.0000e+00\n",
      "Epoch 9/10\n",
      "4246/4246 [==============================] - 246s - loss: 1.0117 - acc: 0.6488 - val_loss: 13.8915 - val_acc: 0.0000e+00\n",
      "Epoch 10/10\n",
      "4246/4246 [==============================] - 231s - loss: 0.8771 - acc: 0.6945 - val_loss: 14.7804 - val_acc: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "# train the model on the new data for a few epochs\n",
    "# fine-tune the model\n",
    "epochs = 10\n",
    "tune_history = model_tune.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_split = 0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "997/997 [==============================] - 52s    \n",
      "Test loss: 3.36162013778\n",
      "Test accuracy: 0.428284854564\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the performance on the unused testing set.\n",
    "score_tune = model_tune.evaluate(x_test, y_test, verbose=1)\n",
    "print('Test loss:', score_tune[0])\n",
    "print('Test accuracy:', score_tune[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfIAAAFtCAYAAAD8oehGAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x117b67a10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# here is a visualization of the training process\n",
    "# typically we gain a lot in the beginning and then\n",
    "# training slows down\n",
    "plt.plot(tune_history.history['acc'])\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.title(\"Training Accuracy, Additional Layers\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 input_4\n",
      "1 conv2d_288\n",
      "2 batch_normalization_283\n",
      "3 activation_283\n",
      "4 conv2d_289\n",
      "5 batch_normalization_284\n",
      "6 activation_284\n",
      "7 conv2d_290\n",
      "8 batch_normalization_285\n",
      "9 activation_285\n",
      "10 max_pooling2d_18\n",
      "11 conv2d_291\n",
      "12 batch_normalization_286\n",
      "13 activation_286\n",
      "14 conv2d_292\n",
      "15 batch_normalization_287\n",
      "16 activation_287\n",
      "17 max_pooling2d_19\n",
      "18 conv2d_296\n",
      "19 batch_normalization_291\n",
      "20 activation_291\n",
      "21 conv2d_294\n",
      "22 conv2d_297\n",
      "23 batch_normalization_289\n",
      "24 batch_normalization_292\n",
      "25 activation_289\n",
      "26 activation_292\n",
      "27 average_pooling2d_28\n",
      "28 conv2d_293\n",
      "29 conv2d_295\n",
      "30 conv2d_298\n",
      "31 conv2d_299\n",
      "32 batch_normalization_288\n",
      "33 batch_normalization_290\n",
      "34 batch_normalization_293\n",
      "35 batch_normalization_294\n",
      "36 activation_288\n",
      "37 activation_290\n",
      "38 activation_293\n",
      "39 activation_294\n",
      "40 mixed0\n",
      "41 conv2d_303\n",
      "42 batch_normalization_298\n",
      "43 activation_298\n",
      "44 conv2d_301\n",
      "45 conv2d_304\n",
      "46 batch_normalization_296\n",
      "47 batch_normalization_299\n",
      "48 activation_296\n",
      "49 activation_299\n",
      "50 average_pooling2d_29\n",
      "51 conv2d_300\n",
      "52 conv2d_302\n",
      "53 conv2d_305\n",
      "54 conv2d_306\n",
      "55 batch_normalization_295\n",
      "56 batch_normalization_297\n",
      "57 batch_normalization_300\n",
      "58 batch_normalization_301\n",
      "59 activation_295\n",
      "60 activation_297\n",
      "61 activation_300\n",
      "62 activation_301\n",
      "63 mixed1\n",
      "64 conv2d_310\n",
      "65 batch_normalization_305\n",
      "66 activation_305\n",
      "67 conv2d_308\n",
      "68 conv2d_311\n",
      "69 batch_normalization_303\n",
      "70 batch_normalization_306\n",
      "71 activation_303\n",
      "72 activation_306\n",
      "73 average_pooling2d_30\n",
      "74 conv2d_307\n",
      "75 conv2d_309\n",
      "76 conv2d_312\n",
      "77 conv2d_313\n",
      "78 batch_normalization_302\n",
      "79 batch_normalization_304\n",
      "80 batch_normalization_307\n",
      "81 batch_normalization_308\n",
      "82 activation_302\n",
      "83 activation_304\n",
      "84 activation_307\n",
      "85 activation_308\n",
      "86 mixed2\n",
      "87 conv2d_315\n",
      "88 batch_normalization_310\n",
      "89 activation_310\n",
      "90 conv2d_316\n",
      "91 batch_normalization_311\n",
      "92 activation_311\n",
      "93 conv2d_314\n",
      "94 conv2d_317\n",
      "95 batch_normalization_309\n",
      "96 batch_normalization_312\n",
      "97 activation_309\n",
      "98 activation_312\n",
      "99 max_pooling2d_20\n",
      "100 mixed3\n",
      "101 conv2d_322\n",
      "102 batch_normalization_317\n",
      "103 activation_317\n",
      "104 conv2d_323\n",
      "105 batch_normalization_318\n",
      "106 activation_318\n",
      "107 conv2d_319\n",
      "108 conv2d_324\n",
      "109 batch_normalization_314\n",
      "110 batch_normalization_319\n",
      "111 activation_314\n",
      "112 activation_319\n",
      "113 conv2d_320\n",
      "114 conv2d_325\n",
      "115 batch_normalization_315\n",
      "116 batch_normalization_320\n",
      "117 activation_315\n",
      "118 activation_320\n",
      "119 average_pooling2d_31\n",
      "120 conv2d_318\n",
      "121 conv2d_321\n",
      "122 conv2d_326\n",
      "123 conv2d_327\n",
      "124 batch_normalization_313\n",
      "125 batch_normalization_316\n",
      "126 batch_normalization_321\n",
      "127 batch_normalization_322\n",
      "128 activation_313\n",
      "129 activation_316\n",
      "130 activation_321\n",
      "131 activation_322\n",
      "132 mixed4\n",
      "133 conv2d_332\n",
      "134 batch_normalization_327\n",
      "135 activation_327\n",
      "136 conv2d_333\n",
      "137 batch_normalization_328\n",
      "138 activation_328\n",
      "139 conv2d_329\n",
      "140 conv2d_334\n",
      "141 batch_normalization_324\n",
      "142 batch_normalization_329\n",
      "143 activation_324\n",
      "144 activation_329\n",
      "145 conv2d_330\n",
      "146 conv2d_335\n",
      "147 batch_normalization_325\n",
      "148 batch_normalization_330\n",
      "149 activation_325\n",
      "150 activation_330\n",
      "151 average_pooling2d_32\n",
      "152 conv2d_328\n",
      "153 conv2d_331\n",
      "154 conv2d_336\n",
      "155 conv2d_337\n",
      "156 batch_normalization_323\n",
      "157 batch_normalization_326\n",
      "158 batch_normalization_331\n",
      "159 batch_normalization_332\n",
      "160 activation_323\n",
      "161 activation_326\n",
      "162 activation_331\n",
      "163 activation_332\n",
      "164 mixed5\n",
      "165 conv2d_342\n",
      "166 batch_normalization_337\n",
      "167 activation_337\n",
      "168 conv2d_343\n",
      "169 batch_normalization_338\n",
      "170 activation_338\n",
      "171 conv2d_339\n",
      "172 conv2d_344\n",
      "173 batch_normalization_334\n",
      "174 batch_normalization_339\n",
      "175 activation_334\n",
      "176 activation_339\n",
      "177 conv2d_340\n",
      "178 conv2d_345\n",
      "179 batch_normalization_335\n",
      "180 batch_normalization_340\n",
      "181 activation_335\n",
      "182 activation_340\n",
      "183 average_pooling2d_33\n",
      "184 conv2d_338\n",
      "185 conv2d_341\n",
      "186 conv2d_346\n",
      "187 conv2d_347\n",
      "188 batch_normalization_333\n",
      "189 batch_normalization_336\n",
      "190 batch_normalization_341\n",
      "191 batch_normalization_342\n",
      "192 activation_333\n",
      "193 activation_336\n",
      "194 activation_341\n",
      "195 activation_342\n",
      "196 mixed6\n",
      "197 conv2d_352\n",
      "198 batch_normalization_347\n",
      "199 activation_347\n",
      "200 conv2d_353\n",
      "201 batch_normalization_348\n",
      "202 activation_348\n",
      "203 conv2d_349\n",
      "204 conv2d_354\n",
      "205 batch_normalization_344\n",
      "206 batch_normalization_349\n",
      "207 activation_344\n",
      "208 activation_349\n",
      "209 conv2d_350\n",
      "210 conv2d_355\n",
      "211 batch_normalization_345\n",
      "212 batch_normalization_350\n",
      "213 activation_345\n",
      "214 activation_350\n",
      "215 average_pooling2d_34\n",
      "216 conv2d_348\n",
      "217 conv2d_351\n",
      "218 conv2d_356\n",
      "219 conv2d_357\n",
      "220 batch_normalization_343\n",
      "221 batch_normalization_346\n",
      "222 batch_normalization_351\n",
      "223 batch_normalization_352\n",
      "224 activation_343\n",
      "225 activation_346\n",
      "226 activation_351\n",
      "227 activation_352\n",
      "228 mixed7\n",
      "229 conv2d_360\n",
      "230 batch_normalization_355\n",
      "231 activation_355\n",
      "232 conv2d_361\n",
      "233 batch_normalization_356\n",
      "234 activation_356\n",
      "235 conv2d_358\n",
      "236 conv2d_362\n",
      "237 batch_normalization_353\n",
      "238 batch_normalization_357\n",
      "239 activation_353\n",
      "240 activation_357\n",
      "241 conv2d_359\n",
      "242 conv2d_363\n",
      "243 batch_normalization_354\n",
      "244 batch_normalization_358\n",
      "245 activation_354\n",
      "246 activation_358\n",
      "247 max_pooling2d_21\n",
      "248 mixed8\n",
      "249 conv2d_368\n",
      "250 batch_normalization_363\n",
      "251 activation_363\n",
      "252 conv2d_365\n",
      "253 conv2d_369\n",
      "254 batch_normalization_360\n",
      "255 batch_normalization_364\n",
      "256 activation_360\n",
      "257 activation_364\n",
      "258 conv2d_366\n",
      "259 conv2d_367\n",
      "260 conv2d_370\n",
      "261 conv2d_371\n",
      "262 average_pooling2d_35\n",
      "263 conv2d_364\n",
      "264 batch_normalization_361\n",
      "265 batch_normalization_362\n",
      "266 batch_normalization_365\n",
      "267 batch_normalization_366\n",
      "268 conv2d_372\n",
      "269 batch_normalization_359\n",
      "270 activation_361\n",
      "271 activation_362\n",
      "272 activation_365\n",
      "273 activation_366\n",
      "274 batch_normalization_367\n",
      "275 activation_359\n",
      "276 mixed9_0\n",
      "277 concatenate_7\n",
      "278 activation_367\n",
      "279 mixed9\n",
      "280 conv2d_377\n",
      "281 batch_normalization_372\n",
      "282 activation_372\n",
      "283 conv2d_374\n",
      "284 conv2d_378\n",
      "285 batch_normalization_369\n",
      "286 batch_normalization_373\n",
      "287 activation_369\n",
      "288 activation_373\n",
      "289 conv2d_375\n",
      "290 conv2d_376\n",
      "291 conv2d_379\n",
      "292 conv2d_380\n",
      "293 average_pooling2d_36\n",
      "294 conv2d_373\n",
      "295 batch_normalization_370\n",
      "296 batch_normalization_371\n",
      "297 batch_normalization_374\n",
      "298 batch_normalization_375\n",
      "299 conv2d_381\n",
      "300 batch_normalization_368\n",
      "301 activation_370\n",
      "302 activation_371\n",
      "303 activation_374\n",
      "304 activation_375\n",
      "305 batch_normalization_376\n",
      "306 activation_368\n",
      "307 mixed9_1\n",
      "308 concatenate_8\n",
      "309 activation_376\n",
      "310 mixed10\n"
     ]
    }
   ],
   "source": [
    "# at this point, the top layers are well trained and we can start fine-tuning\n",
    "# convolutional layers from inception V3. We will freeze the bottom N layers\n",
    "# and train the remaining top layers.\n",
    "\n",
    "# let's visualize layer names and layer indices to see how many layers\n",
    "# we should freeze:\n",
    "for i, layer in enumerate(base_model.layers):\n",
    "   print(i, layer.name)\n",
    "\n",
    "# we chose to train the top 2 inception blocks, i.e. we will freeze\n",
    "# the first 172 layers and unfreeze the rest:\n",
    "for layer in model.layers[:172]:\n",
    "   layer.trainable = False\n",
    "for layer in model.layers[172:]:\n",
    "   layer.trainable = True\n",
    "\n",
    "# we need to recompile the model for these modifications to take effect\n",
    "# we use SGD with a low learning rate\n",
    "model.compile(optimizer=SGD(lr=0.0001, momentum=0.9), loss='categorical_crossentropy',  metrics=[eval_metric])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4246 samples, validate on 750 samples\n",
      "Epoch 1/50\n",
      "4246/4246 [==============================] - 236s - loss: 0.9673 - acc: 0.6585 - val_loss: 14.8387 - val_acc: 0.0000e+00\n",
      "Epoch 2/50\n",
      "4246/4246 [==============================] - 232s - loss: 0.8212 - acc: 0.7146 - val_loss: 15.2516 - val_acc: 0.0000e+00\n",
      "Epoch 3/50\n",
      "4246/4246 [==============================] - 229s - loss: 0.7637 - acc: 0.7390 - val_loss: 15.0134 - val_acc: 0.0013\n",
      "Epoch 4/50\n",
      "4246/4246 [==============================] - 224s - loss: 0.7839 - acc: 0.7315 - val_loss: 14.2588 - val_acc: 0.0013\n",
      "Epoch 5/50\n",
      "4246/4246 [==============================] - 222s - loss: 0.6416 - acc: 0.7734 - val_loss: 15.1884 - val_acc: 0.0013\n",
      "Epoch 6/50\n",
      "4246/4246 [==============================] - 222s - loss: 0.7026 - acc: 0.7654 - val_loss: 14.9500 - val_acc: 0.0013\n",
      "Epoch 7/50\n",
      "4246/4246 [==============================] - 223s - loss: 0.6334 - acc: 0.7862 - val_loss: 15.5382 - val_acc: 0.0013\n",
      "Epoch 8/50\n",
      "4246/4246 [==============================] - 222s - loss: 0.5590 - acc: 0.8168 - val_loss: 15.6616 - val_acc: 0.0013\n",
      "Epoch 9/50\n",
      "4246/4246 [==============================] - 219s - loss: 0.5612 - acc: 0.8161 - val_loss: 15.5792 - val_acc: 0.0027\n",
      "Epoch 10/50\n",
      "4246/4246 [==============================] - 219s - loss: 0.5553 - acc: 0.8099 - val_loss: 14.4660 - val_acc: 0.0027\n",
      "Epoch 11/50\n",
      "4246/4246 [==============================] - 220s - loss: 0.4854 - acc: 0.8460 - val_loss: 15.7884 - val_acc: 0.0027\n",
      "Epoch 12/50\n",
      "4246/4246 [==============================] - 220s - loss: 0.4902 - acc: 0.8380 - val_loss: 15.0478 - val_acc: 0.0013\n",
      "Epoch 13/50\n",
      "4246/4246 [==============================] - 219s - loss: 0.4113 - acc: 0.8782 - val_loss: 15.8910 - val_acc: 0.0027\n",
      "Epoch 14/50\n",
      "4246/4246 [==============================] - 254s - loss: 0.4364 - acc: 0.8573 - val_loss: 15.5184 - val_acc: 0.0027\n",
      "Epoch 15/50\n",
      "4246/4246 [==============================] - 272s - loss: 0.3812 - acc: 0.8844 - val_loss: 15.9560 - val_acc: 0.0027\n",
      "Epoch 16/50\n",
      "4246/4246 [==============================] - 272s - loss: 0.4190 - acc: 0.8794 - val_loss: 15.9326 - val_acc: 0.0040\n",
      "Epoch 17/50\n",
      "4246/4246 [==============================] - 272s - loss: 0.3806 - acc: 0.8855 - val_loss: 15.8601 - val_acc: 0.0040\n",
      "Epoch 18/50\n",
      "4246/4246 [==============================] - 271s - loss: 0.3770 - acc: 0.8804 - val_loss: 15.5851 - val_acc: 0.0040\n",
      "Epoch 19/50\n",
      "4246/4246 [==============================] - 273s - loss: 0.2962 - acc: 0.9192 - val_loss: 15.8931 - val_acc: 0.0040\n",
      "Epoch 20/50\n",
      "4246/4246 [==============================] - 271s - loss: 0.3238 - acc: 0.9091 - val_loss: 15.9671 - val_acc: 0.0040\n",
      "Epoch 21/50\n",
      "4246/4246 [==============================] - 273s - loss: 0.2818 - acc: 0.9211 - val_loss: 15.8156 - val_acc: 0.0040\n",
      "Epoch 22/50\n",
      "4246/4246 [==============================] - 271s - loss: 0.2877 - acc: 0.9246 - val_loss: 15.9677 - val_acc: 0.0027\n",
      "Epoch 23/50\n",
      "4246/4246 [==============================] - 273s - loss: 0.2448 - acc: 0.9310 - val_loss: 15.9789 - val_acc: 0.0040\n",
      "Epoch 24/50\n",
      "4246/4246 [==============================] - 271s - loss: 0.2155 - acc: 0.9421 - val_loss: 15.9541 - val_acc: 0.0040\n",
      "Epoch 25/50\n",
      "4246/4246 [==============================] - 271s - loss: 0.2511 - acc: 0.9232 - val_loss: 15.9659 - val_acc: 0.0040\n",
      "Epoch 26/50\n",
      "4246/4246 [==============================] - 273s - loss: 0.2638 - acc: 0.9147 - val_loss: 15.8972 - val_acc: 0.0040\n",
      "Epoch 27/50\n",
      "4246/4246 [==============================] - 272s - loss: 0.2114 - acc: 0.9454 - val_loss: 15.9609 - val_acc: 0.0040\n",
      "Epoch 28/50\n",
      "4246/4246 [==============================] - 273s - loss: 0.2019 - acc: 0.9423 - val_loss: 15.9754 - val_acc: 0.0040\n",
      "Epoch 29/50\n",
      "4246/4246 [==============================] - 271s - loss: 0.1933 - acc: 0.9510 - val_loss: 15.9613 - val_acc: 0.0040\n",
      "Epoch 30/50\n",
      "4246/4246 [==============================] - 273s - loss: 0.2221 - acc: 0.9376 - val_loss: 15.9481 - val_acc: 0.0027\n",
      "Epoch 31/50\n",
      "4246/4246 [==============================] - 271s - loss: 0.2679 - acc: 0.9242 - val_loss: 15.8530 - val_acc: 0.0040\n",
      "Epoch 32/50\n",
      "4246/4246 [==============================] - 220s - loss: 0.1403 - acc: 0.9623 - val_loss: 15.9796 - val_acc: 0.0040\n",
      "Epoch 33/50\n",
      "4246/4246 [==============================] - 219s - loss: 0.2248 - acc: 0.9338 - val_loss: 15.8625 - val_acc: 0.0040\n",
      "Epoch 34/50\n",
      "4246/4246 [==============================] - 237s - loss: 0.1148 - acc: 0.9699 - val_loss: 16.0011 - val_acc: 0.0040\n",
      "Epoch 35/50\n",
      "4246/4246 [==============================] - 253s - loss: 0.2019 - acc: 0.9496 - val_loss: 15.9719 - val_acc: 0.0040\n",
      "Epoch 36/50\n",
      "4246/4246 [==============================] - 219s - loss: 0.1201 - acc: 0.9739 - val_loss: 16.0066 - val_acc: 0.0040\n",
      "Epoch 37/50\n",
      "4246/4246 [==============================] - 219s - loss: 0.3119 - acc: 0.9319 - val_loss: 15.9750 - val_acc: 0.0040\n",
      "Epoch 38/50\n",
      "4246/4246 [==============================] - 239s - loss: 0.1118 - acc: 0.9736 - val_loss: 16.0046 - val_acc: 0.0040\n",
      "Epoch 39/50\n",
      "4246/4246 [==============================] - 272s - loss: 0.1270 - acc: 0.9670 - val_loss: 15.9916 - val_acc: 0.0027\n",
      "Epoch 40/50\n",
      "4246/4246 [==============================] - 273s - loss: 0.3000 - acc: 0.9378 - val_loss: 15.9926 - val_acc: 0.0040\n",
      "Epoch 41/50\n",
      "4246/4246 [==============================] - 271s - loss: 0.0728 - acc: 0.9870 - val_loss: 15.9939 - val_acc: 0.0040\n",
      "Epoch 42/50\n",
      "4246/4246 [==============================] - 222s - loss: 0.1650 - acc: 0.9578 - val_loss: 15.9618 - val_acc: 0.0040\n",
      "Epoch 43/50\n",
      "4246/4246 [==============================] - 233s - loss: 0.1718 - acc: 0.9593 - val_loss: 15.9471 - val_acc: 0.0040\n",
      "Epoch 44/50\n",
      "4246/4246 [==============================] - 228s - loss: 0.1441 - acc: 0.9651 - val_loss: 15.7448 - val_acc: 0.0040\n",
      "Epoch 45/50\n",
      "4246/4246 [==============================] - 222s - loss: 0.0454 - acc: 0.9925 - val_loss: 16.0145 - val_acc: 0.0040\n",
      "Epoch 46/50\n",
      "4246/4246 [==============================] - 224s - loss: 0.2028 - acc: 0.9541 - val_loss: 15.9981 - val_acc: 0.0040\n",
      "Epoch 47/50\n",
      "4246/4246 [==============================] - 244s - loss: 0.1532 - acc: 0.9593 - val_loss: 15.8998 - val_acc: 0.0040\n",
      "Epoch 48/50\n",
      "4246/4246 [==============================] - 222s - loss: 0.0516 - acc: 0.9911 - val_loss: 16.0034 - val_acc: 0.0040\n",
      "Epoch 49/50\n",
      "4246/4246 [==============================] - 223s - loss: 0.1488 - acc: 0.9621 - val_loss: 15.9699 - val_acc: 0.0040\n",
      "Epoch 50/50\n",
      "4246/4246 [==============================] - 2079s - loss: 0.0792 - acc: 0.9873 - val_loss: 16.0042 - val_acc: 0.0040\n"
     ]
    }
   ],
   "source": [
    "# Fine tune the new model, using the \"fine\" parameters of SGD previously defined.\n",
    "epochs = 50\n",
    "tune_history = model_tune.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_split = 0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "997/997 [==============================] - 53s    \n",
      "Test loss: 3.13101614442\n",
      "Test accuracy: 0.697091273821\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the performance on the unused testing set.\n",
    "score_tune = model_tune.evaluate(x_test, y_test, verbose=1)\n",
    "print('Test loss:', score_tune[0])\n",
    "print('Test accuracy:', score_tune[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfoAAAFtCAYAAADvdqiyAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\niZMAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x117b0a690>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# here is a visualization of the training process\n",
    "# typically we gain a lot in the beginning and then\n",
    "# training slows down\n",
    "plt.plot(tune_history.history['acc'])\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.title(\"Training Accuracy, Fine-Tuning Prebuilt Model\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
