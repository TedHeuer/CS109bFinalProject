{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Milestone 3: Traditional statistical and machine learning methods, due Wednesday, April 19, 2017\n",
    "\n",
    "Think about how you would address the genre prediction problem with traditional statistical or machine learning methods. This includes everything you learned about modeling in this course before the deep learning part. Implement your ideas and compare different classifiers. Report your results and discuss what challenges you faced and how you overcame them. What works and what does not? If there are parts that do not work as expected, make sure to discuss briefly what you think is the cause and how you would address this if you would have more time and resources. \n",
    "\n",
    "You do not necessarily need to use the movie posters for this step, but even without a background in computer vision, there are very simple features you can extract from the posters to help guide a traditional machine learning model. Think about the PCA lecture for example, or how to use clustering to extract color information. In addition to considering the movie posters it would be worthwhile to have a look at the metadata that IMDb provides. \n",
    "\n",
    "You could use Spark and the [ML library](https://spark.apache.org/docs/latest/ml-features.html#word2vec) to build your model features from the data. This may be especially beneficial if you use additional data, e.g., in text form.\n",
    "\n",
    "You also need to think about how you are going to evaluate your classifier. Which metrics or scores will you report to show how good the performance is?\n",
    "\n",
    "The notebook to submit this week should at least include:\n",
    "\n",
    "- Detailed description and implementation of two different models\n",
    "- Description of your performance metrics\n",
    "- Careful performance evaluations for both models\n",
    "- Visualizations of the metrics for performance evaluation\n",
    "- Discussion of the differences between the models, their strengths, weaknesses, etc. \n",
    "- Discussion of the performances you achieved, and how you might be able to improve them in the future\n",
    "\n",
    "#### Preliminary Peer Assessment\n",
    "\n",
    "It is important to provide positive feedback to people who truly worked hard for the good of the team and to also make suggestions to those you perceived not to be working as effectively on team tasks. We ask you to provide an honest assessment of the contributions of the members of your team, including yourself. The feedback you provide should reflect your judgment of each team member’s:\n",
    "\n",
    "- Preparation – were they prepared during team meetings?\n",
    "- Contribution – did they contribute productively to the team discussion and work?\n",
    "- Respect for others’ ideas – did they encourage others to contribute their ideas?\n",
    "- Flexibility – were they flexible when disagreements occurred?\n",
    "\n",
    "Your teammate’s assessment of your contributions and the accuracy of your self-assessment will be considered as part of your overall project score.\n",
    "\n",
    "Preliminary Peer Assessment: [https://goo.gl/forms/WOYC7pwRCSU0yV3l1](https://goo.gl/forms/WOYC7pwRCSU0yV3l1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "from sklearn import linear_model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn import preprocessing\n",
    "from sklearn import tree\n",
    "from sklearn import ensemble\n",
    "from sklearn.multiclass import OneVsOneClassifier\n",
    "from sklearn.cross_validation import KFold\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "import StringIO\n",
    "from PIL import Image\n",
    "import urllib\n",
    "from random import sample\n",
    "from imdb import IMDb\n",
    "import tmdbsimple as tmdb\n",
    "import time\n",
    "tmdb.API_KEY = 'c5d41f08e55fca6e9f5fc0b6d1735540'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#read in genre and movie id multi class\n",
    "mmc = pd.read_csv('C:\\Users\\Chad\\Desktop\\Data Science 2\\Project\\ms3\\y_labels_multiclass2.csv')\n",
    "\n",
    "#access pull infomration from api with smaller subset first \n",
    "#rowindex =  np.array(sample(xrange(len(mmc)), 2000))\n",
    "#mmcr = mmc.ix[rowindex]\n",
    "#mmcr = mmcr.reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie_id</th>\n",
       "      <th>genre_id</th>\n",
       "      <th>genre_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>57119</td>\n",
       "      <td>35</td>\n",
       "      <td>Comedy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18607</td>\n",
       "      <td>35</td>\n",
       "      <td>Comedy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>157845</td>\n",
       "      <td>53</td>\n",
       "      <td>Thriller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>37786</td>\n",
       "      <td>10749</td>\n",
       "      <td>Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>164558</td>\n",
       "      <td>99</td>\n",
       "      <td>Documentary</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   movie_id  genre_id   genre_name\n",
       "0     57119        35       Comedy\n",
       "1     18607        35       Comedy\n",
       "2    157845        53     Thriller\n",
       "3     37786     10749      Romance\n",
       "4    164558        99  Documentary"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mmcr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getMovies(tmdb_id):\n",
    "    movie = tmdb.Movies(tmdb_id)\n",
    "    return movie.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#found a nice example of extracting dominate color palette from image, modify a bit for our project\n",
    "#http://stackoverflow.com/a/16216866/190597 (Jaime)\n",
    "#http://stackoverflow.com/a/16840350/190597 (Jaime)\n",
    "\n",
    "def palette(img):\n",
    "    arr = np.asarray(img)\n",
    "    palette, index = np.unique(asvoid(arr).ravel(), return_inverse=True)\n",
    "    palette = palette.view(arr.dtype).reshape(-1, arr.shape[-1])\n",
    "    count = np.bincount(index)\n",
    "    order = np.argsort(count)\n",
    "    return palette[order[::-1]]\n",
    "\n",
    "def asvoid(arr):\n",
    "    arr = np.ascontiguousarray(arr)\n",
    "    return arr.view(np.dtype((np.void, arr.dtype.itemsize * arr.shape[-1])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#generate a pallatte score for the top 5 dominate color in this image\n",
    "#calculate color intensity for top 5 dominate color\n",
    "#calcuate average red, blue, green scale\n",
    "def getPaletteScore(mpath):\n",
    "    base_url = \"https://image.tmdb.org/t/p/\"\n",
    "    file_size = \"w500\"\n",
    "    poster_path = mpath \n",
    "    poster_url = base_url+file_size+poster_path\n",
    "    img = Image.open(urllib.urlopen(poster_url), 'r').convert('RGB')\n",
    "    palettescore = np.sum(palette(img)[:5], axis = 1)\n",
    "    avgRBG = np.mean(palette(img)[:5], axis = 0)\n",
    "    return palettescore, avgRBG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "idx = range(0, len(mmc))\n",
    "cols = ['genre_name', 'movie_id', 'popularity', 'budget', 'revenue', 'pal_intensity_1', 'pal_intensity_2', 'pal_intensity_3', \n",
    "        'pal_intensity_4', 'pal_intensity_5', 'avg_red', 'avg_blue', 'avg_green']\n",
    "df = pd.DataFrame(index=idx, columns=cols)\n",
    "\n",
    "for i in range(0,len(mmc)):\n",
    "    movie = getMovies(mmc.ix[i, 'movie_id'])\n",
    "    pal_score, avgRBG = getPaletteScore(movie['poster_path'])\n",
    "    df['genre_name'][i] = mmc.ix[i, 'genre_name']\n",
    "    df['id'][i] = mmc.ix[i, 'movie_id']\n",
    "    df['popularity'][i] = movie['popularity']\n",
    "    df['budget'][i] = movie['budget']\n",
    "    df['revenue'][i] = movie['revenue']\n",
    "    df['pal_intensity_1'][i] = pal_score[0]\n",
    "    df['pal_intensity_2'][i] = pal_score[1]\n",
    "    df['pal_intensity_3'][i] = pal_score[2]\n",
    "    df['pal_intensity_4'][i] = pal_score[3]\n",
    "    df['pal_intensity_5'][i] = pal_score[4]\n",
    "    df['avg_red'][i] = avgRBG[0]\n",
    "    df['avg_blue'][i] = avgRBG[1]\n",
    "    df['avg_green'][i] = avgRBG[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#save to csv\n",
    "df.to_csv('C:\\Users\\Chad\\Desktop\\Data Science 2\\Project\\ms3\\movie_df.csv', sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def split(data):\n",
    "    length = data.shape[0]\n",
    "    indices = range(length)\n",
    "    np.random.shuffle(indices)\n",
    "    train_indices = indices[0:int(length * .7)]\n",
    "    test_indices = indices[int(length * .7):]\n",
    "    train = data.iloc[train_indices]\n",
    "    test = data.iloc[test_indices]\n",
    "    return train, test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train, test = split(df)\n",
    "y_train = train.iloc[:, 0]\n",
    "x_train = train.iloc[:, 2:]\n",
    "y_test = test.iloc[:, 0]\n",
    "x_test = test.iloc[:, 2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5-fold cross validation:\n",
      "Chosen number of trees, depth: 91 , 10\n",
      "Test accuracy: 0.351351351351\n"
     ]
    }
   ],
   "source": [
    "n_trees = np.arange(1, 151, 5)  \n",
    "depths = np.arange(1, 25)   \n",
    "\n",
    "# To keep track of the best model\n",
    "best_score = 0\n",
    "\n",
    "# Run grid search for model with 5-fold cross validation\n",
    "print '5-fold cross validation:'\n",
    "\n",
    "for trees in n_trees:\n",
    "    for depth in depths:\n",
    "        \n",
    "        # Cross validation for every experiment\n",
    "        k_folds = KFold(train.shape[0], n_folds=5, shuffle=True)\n",
    "        scores = []\n",
    "        for train_indices, validation_indices in k_folds:\n",
    "            # Generate training data\n",
    "            x_train_cv = x_train.iloc[train_indices]\n",
    "            y_train_cv = y_train.iloc[train_indices]\n",
    "            # Generate validation data\n",
    "            x_validate = x_train.iloc[validation_indices]\n",
    "            y_validate = y_train.iloc[validation_indices]\n",
    "            \n",
    "            # Fit random forest on training data\n",
    "            model = ensemble.RandomForestClassifier(n_estimators=trees, max_depth=depth)\n",
    "            model.fit(x_train_cv, y_train_cv)\n",
    "            # Score on validation data\n",
    "            scores += [model.score(x_validate, y_validate)]\n",
    "        \n",
    "        # Record and report accuracy\n",
    "        average_score = np.mean(scores)\n",
    "        #print \"Trees:\", trees, \"Depth:\", depth, \"Score:\", average_score\n",
    "        \n",
    "        # Update our record of the best parameters see so far\n",
    "        if average_score > best_score:\n",
    "            best_score = average_score\n",
    "            best_trees = trees\n",
    "            best_depth = depth\n",
    "\n",
    "# Fit model on entire train set using chosen number of trees and depth\n",
    "model = ensemble.RandomForestClassifier(n_estimators=best_trees, max_depth=best_depth)\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "print 'Chosen number of trees, depth:', best_trees, ',', best_depth\n",
    "print 'Test accuracy:', model.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>preds</th>\n",
       "      <th>Action</th>\n",
       "      <th>Animation</th>\n",
       "      <th>Comedy</th>\n",
       "      <th>Documentary</th>\n",
       "      <th>Drama</th>\n",
       "      <th>Romance</th>\n",
       "      <th>Thriller</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>actual</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Action</th>\n",
       "      <td>237</td>\n",
       "      <td>7</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Animation</th>\n",
       "      <td>38</td>\n",
       "      <td>26</td>\n",
       "      <td>81</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Comedy</th>\n",
       "      <td>88</td>\n",
       "      <td>10</td>\n",
       "      <td>361</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>24</td>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Documentary</th>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>54</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Drama</th>\n",
       "      <td>39</td>\n",
       "      <td>5</td>\n",
       "      <td>123</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Romance</th>\n",
       "      <td>70</td>\n",
       "      <td>7</td>\n",
       "      <td>207</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Thriller</th>\n",
       "      <td>117</td>\n",
       "      <td>2</td>\n",
       "      <td>89</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>194</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "preds        Action  Animation  Comedy  Documentary  Drama  Romance  Thriller\n",
       "actual                                                                       \n",
       "Action          237          7     100            0      2       15       154\n",
       "Animation        38         26      81            1      0        6        31\n",
       "Comedy           88         10     361            4      5       24        84\n",
       "Documentary      10          0      54            2      1        2        25\n",
       "Drama            39          5     123            1      3        8        67\n",
       "Romance          70          7     207            1      0       22        70\n",
       "Thriller        117          2      89            0      1       11       194"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = model.predict(x_test)\n",
    "pd.crosstab(y_test, preds, rownames=['actual'], colnames=['preds'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mml = pd.read_csv('C:\\Users\\Chad\\Desktop\\Data Science 2\\Project\\ms3\\mml.csv')\n",
    "mml2 = mml.merge(df, on='movie_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mml_train, mml_test = split(mml2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 1, 1, 1],\n",
       "       [1, 1, 0, ..., 0, 0, 1],\n",
       "       [1, 1, 1, ..., 1, 0, 1],\n",
       "       ..., \n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [1, 1, 1, ..., 1, 0, 0],\n",
       "       [1, 1, 0, ..., 0, 0, 1]])"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_mml_train = mml_train['genre_name_x']\n",
    "x_mml_train = mml_train.iloc[:,3:]\n",
    "y_mml_test = mml_test['genre_name_x']\n",
    "x_mml_test = mml_test.iloc[:,3:]\n",
    "Y_mml_train = MultiLabelBinarizer().fit_transform(y_mml_train)\n",
    "Y_mml_test = MultiLabelBinarizer().fit_transform(y_mml_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5-fold cross validation:\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Can't handle mix of multilabel-indicator and multiclass",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-166-721e96cbe310>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[1;31m#model_mml.fit(x_train_cv_mml, y_train_cv_mml)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[1;31m# Score on validation data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m             \u001b[0mscores_mml\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_validate_mml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_validate_mml\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[1;31m# Record and report accuracy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mc:\\python27\\lib\\site-packages\\sklearn\\base.pyc\u001b[0m in \u001b[0;36mscore\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    308\u001b[0m         \"\"\"\n\u001b[1;32m    309\u001b[0m         \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 310\u001b[0;31m         \u001b[1;32mreturn\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    311\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    312\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mc:\\python27\\lib\\site-packages\\sklearn\\metrics\\classification.pyc\u001b[0m in \u001b[0;36maccuracy_score\u001b[0;34m(y_true, y_pred, normalize, sample_weight)\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m     \u001b[1;31m# Compute accuracy for each possible representation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 172\u001b[0;31m     \u001b[0my_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    173\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0my_type\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'multilabel'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m         \u001b[0mdiffering_labels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcount_nonzero\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mc:\\python27\\lib\\site-packages\\sklearn\\metrics\\classification.pyc\u001b[0m in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     80\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_type\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m         raise ValueError(\"Can't handle mix of {0} and {1}\"\n\u001b[0;32m---> 82\u001b[0;31m                          \"\".format(type_true, type_pred))\n\u001b[0m\u001b[1;32m     83\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[1;31m# We can't have more than one value on y_type => The set is no more needed\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Can't handle mix of multilabel-indicator and multiclass"
     ]
    }
   ],
   "source": [
    "n_trees = np.arange(1, 151, 5)  \n",
    "depths = np.arange(1, 25)   \n",
    "\n",
    "# To keep track of the best model\n",
    "best_score_mml = 0\n",
    "\n",
    "# Run grid search for model with 5-fold cross validation\n",
    "print '5-fold cross validation:'\n",
    "\n",
    "for trees in n_trees:\n",
    "    for depth in depths:\n",
    "        \n",
    "        # Cross validation for every experiment\n",
    "        k_folds_mml = KFold(x_mml_train.shape[0], n_folds=5, shuffle=True)\n",
    "        scores_mml = []\n",
    "        for train_indices, validation_indices in k_folds_mml:\n",
    "            # Generate training data\n",
    "            x_train_cv_mml = x_mml_train.iloc[train_indices]\n",
    "            y_train_cv_mml = Y_mml_train[train_indices]\n",
    "            # Generate validation data\n",
    "            x_validate_mml = x_mml_train.iloc[validation_indices]\n",
    "            y_validate_mml = Y_mml_train[validation_indices]\n",
    "            \n",
    "            # Fit random forest on training data\n",
    "            model_mml = OneVsOneClassifier(ensemble.RandomForestClassifier(n_estimators=trees, max_depth=depth))\n",
    "            model_mml.fit(x_train_cv_mml, y_train_cv_mml)\n",
    "            # Score on validation data\n",
    "            scores_mml += [model.score(x_validate_mml, y_validate_mml)]\n",
    "        \n",
    "        # Record and report accuracy\n",
    "        average_score_mml = np.mean(scores_mml)\n",
    "        #print \"Trees:\", trees, \"Depth:\", depth, \"Score:\", average_score\n",
    "        \n",
    "        # Update our record of the best parameters see so far\n",
    "        if average_score_mml > best_score_mml:\n",
    "            best_score_mml = average_score_mml\n",
    "            best_trees_mml = trees\n",
    "            best_depth_mml = depth\n",
    "\n",
    "# Fit model on entire train set using chosen number of trees and depth\n",
    "model_mml = OneVsOneClassifier(ensemble.RandomForestClassifier(n_estimators=best_trees, max_depth=best_depth))\n",
    "model_mml.fit(x_mml_train, Y_mml_train)\n",
    "\n",
    "print 'Chosen number of trees, depth:', best_trees_mml, ',', best_depth_mml\n",
    "print 'Test accuracy:', model.score(x_mml_test, Y_mml_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "too many indices for array",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-172-e6cc23287aff>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel_mml\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mOneVsOneClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mensemble\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mRandomForestClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_depth\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_mml_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_mml_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32mc:\\python27\\lib\\site-packages\\sklearn\\multiclass.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    515\u001b[0m             delayed(_fit_ovo_binary)(\n\u001b[1;32m    516\u001b[0m                 self.estimator, X, y, self.classes_[i], self.classes_[j])\n\u001b[0;32m--> 517\u001b[0;31m             for i in range(n_classes) for j in range(i + 1, n_classes))\n\u001b[0m\u001b[1;32m    518\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    519\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mc:\\python27\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    798\u001b[0m             \u001b[1;31m# was dispatched. In particular this covers the edge\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    799\u001b[0m             \u001b[1;31m# case of Parallel used with an exhausted iterator.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 800\u001b[0;31m             \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    801\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    802\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mc:\\python27\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.pyc\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    656\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    657\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 658\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    659\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    660\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mc:\\python27\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.pyc\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    564\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    565\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pool\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 566\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateComputeBatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    567\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    568\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_dispatched_batches\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mc:\\python27\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    178\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mc:\\python27\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mc:\\python27\\lib\\site-packages\\sklearn\\multiclass.pyc\u001b[0m in \u001b[0;36m_fit_ovo_binary\u001b[0;34m(estimator, X, y, i, j)\u001b[0m\n\u001b[1;32m    425\u001b[0m     \u001b[0my_binary\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0my\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m     \u001b[0mind\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 427\u001b[0;31m     \u001b[1;32mreturn\u001b[0m \u001b[0m_fit_binary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mind\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcond\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_binary\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclasses\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    428\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: too many indices for array"
     ]
    }
   ],
   "source": [
    "model_mml = OneVsOneClassifier(ensemble.RandomForestClassifier(n_estimators=10, max_depth=10)).fit(x_mml_train, Y_mml_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
